{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/simseoyoung/Deep-Learning/blob/main/Project/LSTM_AE2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WXN_EK6H32OW"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import tensorflow.keras as keras\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.utils.data as data_utils\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import random\n",
        "import torch\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import copy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Df5h7cWU4AWd",
        "outputId": "8a54b459-0c13-4ffe-8dad-41060fbe8cbc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iE7rV8cXCoz1"
      },
      "source": [
        "[1] Data\n",
        "- Pump sensor data (https://www.kaggle.com/datasets/nphantawee/pump-sensor-data) \n",
        "- April,2018~August,2018 for minutes\n",
        "- 52 sensors\n",
        "- 7 error in it (contains label - Normal, Broken, Recovering)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 835
        },
        "id": "bLWt1ZYP4CFi",
        "outputId": "1c656b56-3190-45f3-e52c-e9cb4c9e8581"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-fff0c060-2ffe-4fe3-80d5-53e26b30c16a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>timestamp</th>\n",
              "      <th>sensor_00</th>\n",
              "      <th>sensor_01</th>\n",
              "      <th>sensor_02</th>\n",
              "      <th>sensor_03</th>\n",
              "      <th>sensor_04</th>\n",
              "      <th>sensor_05</th>\n",
              "      <th>sensor_06</th>\n",
              "      <th>sensor_07</th>\n",
              "      <th>sensor_08</th>\n",
              "      <th>...</th>\n",
              "      <th>sensor_43</th>\n",
              "      <th>sensor_44</th>\n",
              "      <th>sensor_45</th>\n",
              "      <th>sensor_46</th>\n",
              "      <th>sensor_47</th>\n",
              "      <th>sensor_48</th>\n",
              "      <th>sensor_49</th>\n",
              "      <th>sensor_50</th>\n",
              "      <th>sensor_51</th>\n",
              "      <th>machine_status</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2018-04-01 00:00:00</td>\n",
              "      <td>2.465394</td>\n",
              "      <td>47.09201</td>\n",
              "      <td>53.211800</td>\n",
              "      <td>46.310760</td>\n",
              "      <td>634.375000</td>\n",
              "      <td>76.45975</td>\n",
              "      <td>13.41146</td>\n",
              "      <td>16.13136</td>\n",
              "      <td>15.56713</td>\n",
              "      <td>...</td>\n",
              "      <td>41.92708</td>\n",
              "      <td>39.641200</td>\n",
              "      <td>65.68287</td>\n",
              "      <td>50.92593</td>\n",
              "      <td>38.194440</td>\n",
              "      <td>157.9861</td>\n",
              "      <td>67.70834</td>\n",
              "      <td>243.0556</td>\n",
              "      <td>201.3889</td>\n",
              "      <td>NORMAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2018-04-01 00:01:00</td>\n",
              "      <td>2.465394</td>\n",
              "      <td>47.09201</td>\n",
              "      <td>53.211800</td>\n",
              "      <td>46.310760</td>\n",
              "      <td>634.375000</td>\n",
              "      <td>76.45975</td>\n",
              "      <td>13.41146</td>\n",
              "      <td>16.13136</td>\n",
              "      <td>15.56713</td>\n",
              "      <td>...</td>\n",
              "      <td>41.92708</td>\n",
              "      <td>39.641200</td>\n",
              "      <td>65.68287</td>\n",
              "      <td>50.92593</td>\n",
              "      <td>38.194440</td>\n",
              "      <td>157.9861</td>\n",
              "      <td>67.70834</td>\n",
              "      <td>243.0556</td>\n",
              "      <td>201.3889</td>\n",
              "      <td>NORMAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2018-04-01 00:02:00</td>\n",
              "      <td>2.444734</td>\n",
              "      <td>47.35243</td>\n",
              "      <td>53.211800</td>\n",
              "      <td>46.397570</td>\n",
              "      <td>638.888900</td>\n",
              "      <td>73.54598</td>\n",
              "      <td>13.32465</td>\n",
              "      <td>16.03733</td>\n",
              "      <td>15.61777</td>\n",
              "      <td>...</td>\n",
              "      <td>41.66666</td>\n",
              "      <td>39.351852</td>\n",
              "      <td>65.39352</td>\n",
              "      <td>51.21528</td>\n",
              "      <td>38.194443</td>\n",
              "      <td>155.9606</td>\n",
              "      <td>67.12963</td>\n",
              "      <td>241.3194</td>\n",
              "      <td>203.7037</td>\n",
              "      <td>NORMAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2018-04-01 00:03:00</td>\n",
              "      <td>2.460474</td>\n",
              "      <td>47.09201</td>\n",
              "      <td>53.168400</td>\n",
              "      <td>46.397568</td>\n",
              "      <td>628.125000</td>\n",
              "      <td>76.98898</td>\n",
              "      <td>13.31742</td>\n",
              "      <td>16.24711</td>\n",
              "      <td>15.69734</td>\n",
              "      <td>...</td>\n",
              "      <td>40.88541</td>\n",
              "      <td>39.062500</td>\n",
              "      <td>64.81481</td>\n",
              "      <td>51.21528</td>\n",
              "      <td>38.194440</td>\n",
              "      <td>155.9606</td>\n",
              "      <td>66.84028</td>\n",
              "      <td>240.4514</td>\n",
              "      <td>203.1250</td>\n",
              "      <td>NORMAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2018-04-01 00:04:00</td>\n",
              "      <td>2.445718</td>\n",
              "      <td>47.13541</td>\n",
              "      <td>53.211800</td>\n",
              "      <td>46.397568</td>\n",
              "      <td>636.458300</td>\n",
              "      <td>76.58897</td>\n",
              "      <td>13.35359</td>\n",
              "      <td>16.21094</td>\n",
              "      <td>15.69734</td>\n",
              "      <td>...</td>\n",
              "      <td>41.40625</td>\n",
              "      <td>38.773150</td>\n",
              "      <td>65.10416</td>\n",
              "      <td>51.79398</td>\n",
              "      <td>38.773150</td>\n",
              "      <td>158.2755</td>\n",
              "      <td>66.55093</td>\n",
              "      <td>242.1875</td>\n",
              "      <td>201.3889</td>\n",
              "      <td>NORMAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>220315</th>\n",
              "      <td>2018-08-31 23:55:00</td>\n",
              "      <td>2.407350</td>\n",
              "      <td>47.69965</td>\n",
              "      <td>50.520830</td>\n",
              "      <td>43.142361</td>\n",
              "      <td>634.722229</td>\n",
              "      <td>64.59095</td>\n",
              "      <td>15.11863</td>\n",
              "      <td>16.65220</td>\n",
              "      <td>15.65393</td>\n",
              "      <td>...</td>\n",
              "      <td>38.28125</td>\n",
              "      <td>68.287030</td>\n",
              "      <td>52.37268</td>\n",
              "      <td>48.32176</td>\n",
              "      <td>41.087960</td>\n",
              "      <td>212.3843</td>\n",
              "      <td>153.64580</td>\n",
              "      <td>NaN</td>\n",
              "      <td>231.1921</td>\n",
              "      <td>NORMAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>220316</th>\n",
              "      <td>2018-08-31 23:56:00</td>\n",
              "      <td>2.400463</td>\n",
              "      <td>47.69965</td>\n",
              "      <td>50.564240</td>\n",
              "      <td>43.142361</td>\n",
              "      <td>630.902771</td>\n",
              "      <td>65.83363</td>\n",
              "      <td>15.15480</td>\n",
              "      <td>16.70284</td>\n",
              "      <td>15.65393</td>\n",
              "      <td>...</td>\n",
              "      <td>38.28125</td>\n",
              "      <td>66.840280</td>\n",
              "      <td>50.63657</td>\n",
              "      <td>48.03241</td>\n",
              "      <td>40.798610</td>\n",
              "      <td>213.8310</td>\n",
              "      <td>156.25000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>231.1921</td>\n",
              "      <td>NORMAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>220317</th>\n",
              "      <td>2018-08-31 23:57:00</td>\n",
              "      <td>2.396528</td>\n",
              "      <td>47.69965</td>\n",
              "      <td>50.520830</td>\n",
              "      <td>43.142361</td>\n",
              "      <td>625.925903</td>\n",
              "      <td>67.29445</td>\n",
              "      <td>15.08970</td>\n",
              "      <td>16.70284</td>\n",
              "      <td>15.69734</td>\n",
              "      <td>...</td>\n",
              "      <td>39.06250</td>\n",
              "      <td>65.393520</td>\n",
              "      <td>48.90046</td>\n",
              "      <td>48.03241</td>\n",
              "      <td>40.798610</td>\n",
              "      <td>217.3032</td>\n",
              "      <td>155.38190</td>\n",
              "      <td>NaN</td>\n",
              "      <td>232.0602</td>\n",
              "      <td>NORMAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>220318</th>\n",
              "      <td>2018-08-31 23:58:00</td>\n",
              "      <td>2.406366</td>\n",
              "      <td>47.69965</td>\n",
              "      <td>50.520832</td>\n",
              "      <td>43.142361</td>\n",
              "      <td>635.648100</td>\n",
              "      <td>65.09175</td>\n",
              "      <td>15.11863</td>\n",
              "      <td>16.56539</td>\n",
              "      <td>15.74074</td>\n",
              "      <td>...</td>\n",
              "      <td>40.62500</td>\n",
              "      <td>64.236110</td>\n",
              "      <td>47.74306</td>\n",
              "      <td>48.32176</td>\n",
              "      <td>40.509258</td>\n",
              "      <td>222.5116</td>\n",
              "      <td>153.93520</td>\n",
              "      <td>NaN</td>\n",
              "      <td>234.0856</td>\n",
              "      <td>NORMAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>220319</th>\n",
              "      <td>2018-08-31 23:59:00</td>\n",
              "      <td>2.396528</td>\n",
              "      <td>47.69965</td>\n",
              "      <td>50.520832</td>\n",
              "      <td>43.142361</td>\n",
              "      <td>639.814800</td>\n",
              "      <td>65.45634</td>\n",
              "      <td>15.11863</td>\n",
              "      <td>16.65220</td>\n",
              "      <td>15.65393</td>\n",
              "      <td>...</td>\n",
              "      <td>41.40625</td>\n",
              "      <td>62.789350</td>\n",
              "      <td>46.29630</td>\n",
              "      <td>48.90046</td>\n",
              "      <td>40.219910</td>\n",
              "      <td>227.4306</td>\n",
              "      <td>150.46300</td>\n",
              "      <td>NaN</td>\n",
              "      <td>234.0856</td>\n",
              "      <td>NORMAL</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>220320 rows Ã— 54 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fff0c060-2ffe-4fe3-80d5-53e26b30c16a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fff0c060-2ffe-4fe3-80d5-53e26b30c16a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fff0c060-2ffe-4fe3-80d5-53e26b30c16a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                  timestamp  sensor_00  sensor_01  sensor_02  sensor_03  \\\n",
              "0       2018-04-01 00:00:00   2.465394   47.09201  53.211800  46.310760   \n",
              "1       2018-04-01 00:01:00   2.465394   47.09201  53.211800  46.310760   \n",
              "2       2018-04-01 00:02:00   2.444734   47.35243  53.211800  46.397570   \n",
              "3       2018-04-01 00:03:00   2.460474   47.09201  53.168400  46.397568   \n",
              "4       2018-04-01 00:04:00   2.445718   47.13541  53.211800  46.397568   \n",
              "...                     ...        ...        ...        ...        ...   \n",
              "220315  2018-08-31 23:55:00   2.407350   47.69965  50.520830  43.142361   \n",
              "220316  2018-08-31 23:56:00   2.400463   47.69965  50.564240  43.142361   \n",
              "220317  2018-08-31 23:57:00   2.396528   47.69965  50.520830  43.142361   \n",
              "220318  2018-08-31 23:58:00   2.406366   47.69965  50.520832  43.142361   \n",
              "220319  2018-08-31 23:59:00   2.396528   47.69965  50.520832  43.142361   \n",
              "\n",
              "         sensor_04  sensor_05  sensor_06  sensor_07  sensor_08  ...  \\\n",
              "0       634.375000   76.45975   13.41146   16.13136   15.56713  ...   \n",
              "1       634.375000   76.45975   13.41146   16.13136   15.56713  ...   \n",
              "2       638.888900   73.54598   13.32465   16.03733   15.61777  ...   \n",
              "3       628.125000   76.98898   13.31742   16.24711   15.69734  ...   \n",
              "4       636.458300   76.58897   13.35359   16.21094   15.69734  ...   \n",
              "...            ...        ...        ...        ...        ...  ...   \n",
              "220315  634.722229   64.59095   15.11863   16.65220   15.65393  ...   \n",
              "220316  630.902771   65.83363   15.15480   16.70284   15.65393  ...   \n",
              "220317  625.925903   67.29445   15.08970   16.70284   15.69734  ...   \n",
              "220318  635.648100   65.09175   15.11863   16.56539   15.74074  ...   \n",
              "220319  639.814800   65.45634   15.11863   16.65220   15.65393  ...   \n",
              "\n",
              "        sensor_43  sensor_44  sensor_45  sensor_46  sensor_47  sensor_48  \\\n",
              "0        41.92708  39.641200   65.68287   50.92593  38.194440   157.9861   \n",
              "1        41.92708  39.641200   65.68287   50.92593  38.194440   157.9861   \n",
              "2        41.66666  39.351852   65.39352   51.21528  38.194443   155.9606   \n",
              "3        40.88541  39.062500   64.81481   51.21528  38.194440   155.9606   \n",
              "4        41.40625  38.773150   65.10416   51.79398  38.773150   158.2755   \n",
              "...           ...        ...        ...        ...        ...        ...   \n",
              "220315   38.28125  68.287030   52.37268   48.32176  41.087960   212.3843   \n",
              "220316   38.28125  66.840280   50.63657   48.03241  40.798610   213.8310   \n",
              "220317   39.06250  65.393520   48.90046   48.03241  40.798610   217.3032   \n",
              "220318   40.62500  64.236110   47.74306   48.32176  40.509258   222.5116   \n",
              "220319   41.40625  62.789350   46.29630   48.90046  40.219910   227.4306   \n",
              "\n",
              "        sensor_49  sensor_50  sensor_51  machine_status  \n",
              "0        67.70834   243.0556   201.3889          NORMAL  \n",
              "1        67.70834   243.0556   201.3889          NORMAL  \n",
              "2        67.12963   241.3194   203.7037          NORMAL  \n",
              "3        66.84028   240.4514   203.1250          NORMAL  \n",
              "4        66.55093   242.1875   201.3889          NORMAL  \n",
              "...           ...        ...        ...             ...  \n",
              "220315  153.64580        NaN   231.1921          NORMAL  \n",
              "220316  156.25000        NaN   231.1921          NORMAL  \n",
              "220317  155.38190        NaN   232.0602          NORMAL  \n",
              "220318  153.93520        NaN   234.0856          NORMAL  \n",
              "220319  150.46300        NaN   234.0856          NORMAL  \n",
              "\n",
              "[220320 rows x 54 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data_url = \"/content/drive/MyDrive/ECE 453 project/sensor.csv\"\n",
        "df = pd.read_csv(train_data_url)\n",
        "df = df.iloc[: , 1:]\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "id": "e1ckSW_p4EFh",
        "outputId": "310e825c-ed2f-4309-c4a6-25db2b232861"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fbf68b55b10>"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABBEAAAIXCAYAAADKcsZMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de5hld1kn+u+bdAIOECFJI0jnghgumREnocEL+AgGNNExcfBG+/goyjHMKOhBBsXRAQcdRfToAAKCFwQ5XKJ46RmCgYOZI4pAbpAQQiQnMdA5IJG7Fy6Bd/7Yu6Eoqrp/u3p39urqz+d51tN7r73qu9+qWl29+ltrr13dHQAAAICDOWbVAwAAAABHBiUCAAAAMESJAAAAAAxRIgAAAABDlAgAAADAECUCAAAAMGTHqp745JNP7tNPP31VTw8AAABs4IorrviH7t650WMrKxFOP/30XH755at6egAAAGADVXXzZo95OQMAAAAwRIkAAAAADFEiAAAAAEOUCAAAAMAQJQIAAAAwRIkAAAAADFEiAAAAAEOUCAAAAMAQJQIAAAAwRIkAAAAADFEiAAAAAEOUCAAAAMAQJQIAAAAwRIkAAAAADFEiAAAAAEMOWiJU1e9V1Qeq6h2bPF5V9ZyquqGqrq6qs5c/JgAAALBqI2ci/H6Scw/w+HlJzpgvFyZ5waGPBQAAAEzNQUuE7v7LJB86wCYXJHlpz7w5yV2r6p7LGhAAAACYhmVcE+FeSd675v6++ToAAABgG9lxez5ZVV2Y2Usecuqpp96eTw3wBV5x1b6h7facteswTwIAAEeOZZyJcEuSU9bc3zVf90W6+0Xdvbu7d+/cuXMJTw0AAADcXpZRIuxN8gPzd2n42iQf7e73LSEXAAAAmJCDvpyhql6R5OFJTq6qfUmenuS4JOnu30pycZJvTXJDkn9O8kOHa1gAAABgdQ5aInT3noM83kl+bGkTAQAAAJO0jJczAAAAAEcBJQIAAAAwRIkAAAAADFEiAAAAAEOUCAAAAMAQJQIAAAAwRIkAAAAADFEiAAAAAEOUCAAAAMAQJQIAAAAwRIkAAAAADFEiAAAAAEOUCAAAAMAQJQIAAAAwRIkAAAAADFEiAAAAAEOUCAAAAMAQJQIAAAAwRIkAAAAADFEiAAAAAEOUCAAAAMAQJQIAAAAwRIkAAAAADFEiAAAAAEOUCAAAAMAQJQIAAAAwRIkAAAAADFEiAAAAAEOUCAAAAMAQJQIAAAAwRIkAAAAADFEiAAAAAEOUCAAAAMAQJQIAAAAwRIkAAAAADFEiAAAAAEOUCAAAAMAQJQIAAAAwRIkAAAAADFEiAAAAAEOUCAAAAMAQJQIAAAAwRIkAAAAADFEiAAAAAEOUCAAAAMAQJQIAAAAwRIkAAAAADFEiAAAAAEOUCAAAAMAQJQIAAAAwRIkAAAAADFEiAAAAAEOUCAAAAMAQJQIAAAAwRIkAAAAADFEiAAAAAEOUCAAAAMAQJQIAAAAwRIkAAAAADFEiAAAAAEOUCAAAAMAQJQIAAAAwRIkAAAAADFEiAAAAAEOUCAAAAMAQJQIAAAAwRIkAAAAADFEiAAAAAEOUCAAAAMAQJQIAAAAwRIkAAAAADFEiAAAAAEOUCAAAAMAQJQIAAAAwZKhEqKpzq+r6qrqhqp66weOnVtWlVXVVVV1dVd+6/FEBAACAVTpoiVBVxyZ5XpLzkpyZZE9Vnblus59LclF3n5XkMUmev+xBAQAAgNUaORPhIUlu6O4bu/tTSV6Z5IJ123SSE+a3vzTJ/7+8EQEAAIAp2DGwzb2SvHfN/X1JvmbdNj+f5HVV9cQkd0ryyKVMBwAAAEzGsi6suCfJ73f3riTfmuQPquqLsqvqwqq6vKouv/XWW5f01AAAAMDtYaREuCXJKWvu75qvW+txSS5Kku7+myR3THLy+qDuflF37+7u3Tt37tzaxAAAAMBKjJQIlyU5o6ruXVXHZ3bhxL3rtnlPknOSpKoekFmJ4FQDAAAA2EYOWiJ0921JnpDkkiTXZfYuDNdW1TOq6vz5Zk9O8iNV9fYkr0jy2O7uwzU0AAAAcPsbubBiuvviJBevW/e0NbffmeShyx0NAAAAmJJlXVgRAAAA2OaUCAAAAMAQJQIAAAAwRIkAAAAADFEiAAAAAEOUCAAAAMAQJQIAAAAwRIkAAAAADFEiAAAAAEOUCAAAAMAQJQIAAAAwRIkAAAAADFEiAAAAAEOUCAAAAMAQJQIAAAAwRIkAAAAADFEiAAAAAEOUCAAAAMAQJQIAAAAwRIkAAAAADFEiAAAAAEOUCAAAAMAQJQIAAAAwRIkAAAAADFEiAAAAAEOUCAAAAMAQJQIAAAAwRIkAAAAADFEiAAAAAEOUCAAAAMAQJQIAAAAwRIkAAAAADFEiAAAAAEOUCAAAAMAQJQIAAAAwRIkAAAAADFEiAAAAAEOUCAAAAMAQJQIAAAAwRIkAAAAADFEiAAAAAEOUCAAAAMAQJQIAAAAwRIkAAAAADFEiAAAAAEOUCAAAAMAQJQIAAAAwRIkAAAAADFEiAAAAAEOUCAAAAMAQJQIAAAAwRIkAAAAADFEiAAAAAEOUCAAAAMAQJQIAAAAwRIkAAAAADFEiAAAAAEOUCAAAAMAQJQIAAAAwRIkAAAAADFEiAAAAAEOUCAAAAMAQJQIAAAAwRIkAAAAADFEiAAAAAEOUCAAAAMAQJQIAAAAwRIkAAAAADFEiAAAAAEOUCAAAAMAQJQIAAAAwRIkAAAAADFEiAAAAAEOUCAAAAMCQoRKhqs6tquur6oaqeuom23xPVb2zqq6tqpcvd0wAAABg1XYcbIOqOjbJ85I8Ksm+JJdV1d7ufueabc5I8jNJHtrdH66qux+ugQEAAIDVGDkT4SFJbujuG7v7U0lemeSCddv8SJLndfeHk6S7P7DcMQEAAIBVGykR7pXkvWvu75uvW+u+Se5bVX9dVW+uqnOXNSAAAAAwDQd9OcMCOWckeXiSXUn+sqq+qrs/snajqrowyYVJcuqppy7pqQEAAIDbw8iZCLckOWXN/V3zdWvtS7K3uz/d3Tcl+dvMSoUv0N0v6u7d3b17586dW50ZAAAAWIGREuGyJGdU1b2r6vgkj0myd902f5rZWQipqpMze3nDjUucEwAAAFixg5YI3X1bkickuSTJdUku6u5rq+oZVXX+fLNLknywqt6Z5NIkT+nuDx6uoQEAAIDb39A1Ebr74iQXr1v3tDW3O8lPzhcAAABgGxp5OQMAAACAEgEAAAAYo0QAAAAAhigRAAAAgCFKBAAAAGCIEgEAAAAYokQAAAAAhigRAAAAgCFKBAAAAGCIEgEAAAAYokQAAAAAhigRAAAAgCFKBAAAAGCIEgEAAAAYokQAAAAAhigRAAAAgCFKBAAAAGCIEgEAAAAYokQAAAAAhigRAAAAgCFKBAAAAGCIEgEAAAAYokQAAAAAhigRAAAAgCFKBAAAAGCIEgEAAAAYokQAAAAAhigRAAAAgCFKBAAAAGCIEgEAAAAYokQAAAAAhigRAAAAgCFKBAAAAGCIEgEAAAAYokQAAAAAhigRAAAAgCFKBAAAAGCIEgEAAAAYokQAAAAAhigRAAAAgCFKBAAAAGCIEgEAAAAYokQAAAAAhigRAAAAgCFKBAAAAGCIEgEAAAAYokQAAAAAhigRAAAAgCFKBAAAAGCIEgEAAAAYokQAAAAAhigRAAAAgCFKBAAAAGCIEgEAAAAYokQAAAAAhigRAAAAgCFKBAAAAGCIEgEAAAAYokQAAAAAhigRAAAAgCFKBAAAAGCIEgEAAAAYokQAAAAAhigRAAAAgCFKBAAAAGCIEgEAAAAYokQAAAAAhigRAAAAgCFKBAAAAGCIEgEAAAAYokQAAAAAhigRAAAAgCFKBAAAAGDIUIlQVedW1fVVdUNVPfUA231nVXVV7V7eiAAAAMAUHLREqKpjkzwvyXlJzkyyp6rO3GC7uyT5iSRvWfaQAAAAwOqNnInwkCQ3dPeN3f2pJK9McsEG2/1Ckl9J8oklzgcAAABMxEiJcK8k711zf9983edU1dlJTunu1yxxNgAAAGBCDvnCilV1TJJfT/LkgW0vrKrLq+ryW2+99VCfGgAAALgdjZQItyQ5Zc39XfN1+90lyb9J8r+q6u+SfG2SvRtdXLG7X9Tdu7t7986dO7c+NQAAAHC7GykRLktyRlXdu6qOT/KYJHv3P9jdH+3uk7v79O4+Pcmbk5zf3ZcflokBAACAlThoidDdtyV5QpJLklyX5KLuvraqnlFV5x/uAQEAAIBp2DGyUXdfnOTideuetsm2Dz/0sQAAAICpOeQLKwIAAABHByUCAAAAMESJAAAAAAxRIgAAAABDlAgAAADAECUCAAAAMESJAAAAAAxRIgAAAABDlAgAAADAECUCAAAAMESJAAAAAAxRIgAAAABDlAgAAADAECUCAAAAMESJAAAAAAxRIgAAAABDdqx6AAAAADiSveKqfUPb7Tlr12Ge5PBzJgIAAAAwRIkAAAAADFEiAAAAAEOUCAAAAMAQJQIAAAAwRIkAAAAADFEiAAAAAEOUCAAAAMAQJQIAAAAwRIkAAAAADFEiAAAAAEOUCAAAAMAQJQIAAAAwRIkAAAAADFEiAAAAAEOUCAAAAMAQJQIAAAAwRIkAAAAADFEiAAAAAEOUCAAAAMAQJQIAAAAwRIkAAAAADFEiAAAAAEOUCAAAAMAQJQIAAAAwRIkAAAAADFEiAAAAAEOUCAAAAMAQJQIAAAAwRIkAAAAADFEiAAAAAEOUCAAAAMAQJQIAAAAwRIkAAAAADFEiAAAAAEOUCAAAAMAQJQIAAAAwRIkAAAAADFEiAAAAAEOUCAAAAMAQJQIAAAAwRIkAAAAADFEiAAAAAEOUCAAAAMAQJQIAAAAwRIkAAAAADFEiAAAAAEOUCAAAAMAQJQIAAAAwRIkAAAAADFEiAAAAAEOUCAAAAMAQJQIAAAAwRIkAAAAADFEiAAAAAEOUCAAAAMAQJQIAAAAwZKhEqKpzq+r6qrqhqp66weM/WVXvrKqrq+oNVXXa8kcFAAAAVumgJUJVHZvkeUnOS3Jmkj1Vdea6za5Ksru7H5jkj5I8a9mDAgAAAKs1cibCQ5Lc0N03dvenkrwyyQVrN+juS7v7n+d335xk13LHBAAAAFZtpES4V5L3rrm/b75uM49L8tpDGQoAAACYnh3LDKuq70+yO8k3bvL4hUkuTJJTTz11mU8NAAAAHGYjZyLckuSUNfd3zdd9gap6ZJKfTXJ+d39yo6DuflF37+7u3Tt37tzKvAAAAMCKjJQIlyU5o6ruXVXHJ3lMkr1rN6iqs5K8MLMC4QPLHxMAAABYtYOWCN19W5InJLkkyXVJLurua6vqGVV1/nyzX01y5yR/WFVvq6q9m8QBAAAAR6ihayJ098VJLl637mlrbj9yyXMBAAAAEzPycgYAAAAAJQIAAAAwRokAAAAADFEiAAAAAEOUCAAAAMAQJQIAAAAwRIkAAAAADFEiAAAAAEOUCAAAAMAQJQIAAAAwRIkAAAAADFEiAAAAAEOUCAAAAMAQJQIAAAAwRIkAAAAADFEiAAAAAEOUCAAAAMAQJQIAAAAwRIkAAAAADFEiAAAAAEOUCAAAAMAQJQIAAAAwRIkAAAAADFEiAAAAAEOUCAAAAMAQJQIAAAAwRIkAAAAADFEiAAAAAEOUCAAAAMAQJQIAAAAwRIkAAAAADFEiAAAAAEOUCAAAAMAQJQIAAAAwRIkAAAAADFEiAAAAAEOUCAAAAMAQJQIAAAAwRIkAAAAADFEiAAAAAEOUCAAAAMAQJQIAAAAwRIkAAAAADFEiAAAAAEOUCAAAAMAQJQIAAAAwRIkAAAAADFEiAAAAAEOUCAAAAMCQHaseAAAAAJh5xVX7hrbbc9auwzzJxpyJAAAAAAxRIgAAAABDlAgAAADAECUCAAAAMESJAAAAAAxRIgAAAABDlAgAAADAECUCAAAAMESJAAAAAAzZseoB1nrFVfsOus2es3bdDpMAAAAA6zkTAQAAABiiRAAAAACGKBEAAACAIUoEAAAAYIgSAQAAABiiRAAAAACGKBEAAACAIUoEAAAAYMiOVQ8Am3nFVfuGtttz1q7bNQsAAOBopURg6Ub+w34k/2ddIQEAABytvJwBAAAAGKJEAAAAAIYoEQAAAIAhSgQAAABgyFCJUFXnVtX1VXVDVT11g8fvUFWvmj/+lqo6fdmDAgAAAKt10BKhqo5N8rwk5yU5M8meqjpz3WaPS/Lh7v7KJL+R5FeWPSgAAACwWiNnIjwkyQ3dfWN3fyrJK5NcsG6bC5K8ZH77j5KcU1W1vDEBAACAVdsxsM29krx3zf19Sb5ms226+7aq+miSk5L8wzKG3IpXXLXvoNvsOWvX7TAJAAAAbA8jJcLSVNWFSS6c3/3Hqrp+4MNOzpoy4vsObYRlZX1BziE6KrOW+bU/GrIOgaxDzPJ9PKqzpjiTLFmyZMlabtYUZ5K1jbOOoP9vnLbpI919wCXJ1yW5ZM39n0nyM+u2uSTJ181v75gPVAfLHlmSXL6MnGVmTXEmWbJkyZK13KwpziRLlixZspabNcWZZMmaetbINREuS3JGVd27qo5P8pgke9dtszfJD85vf1eSv+j5dAAAAMD2cNCXM/TsGgdPyOxsg2OT/F53X1tVz8iswdib5HeT/EFV3ZDkQ5kVDQAAAMA2MnRNhO6+OMnF69Y9bc3tTyT57uWO9jkvmmDWFGeSJUuWLFnLzZriTLJkyZIla7lZU5xJlqxJZ5VXHQAAAAAjRq6JAAAAAKBEAAAAAMYoEQAAAIAhSoRtpKruvuoZNlJVJ616hiNBVZ1YVSeueo4jTVWdveoZ1quqE6rqQVV1t1XPsl5VnbyEjLtV1QlLmsd+vyD7/GKmts+zNY5xONrY549sUz++mf+79sCtfvykSoSq+tKqemZVvauqPlRVH6yq6+br7rrE53ntAtueUFW/XFV/UFXft+6x5y/4vPeoqhdU1fOq6qSq+vmquqaqLqqqey6YdeK65aQkb53vEAvtsFV17prbX1pVv1tVV1fVy6vqyxbMeub+A7aq2l1VNyZ5S1XdXFXfuGDWlVX1c1V1n0U+bpOs3VV1aVW9rKpOqarXV9VHq+qyqjprwaw7V9UzquraecatVfXmqnrsFuY6tapeWVW3JnlLZt/DD8zXnb5o3gGe55oFtz9lPsMbq+o/V9Vxax770wWz7l9Vr62q11TVfarq96vqI1X11qp6wIJZZ69bHpRkb1Wdteh/rKrqh9fc3lVVb5jP9aaquu+CWS9bs99/S5J3JPmVJG+rqoXeuWb+s+93quqcqqpFPnaDrPOq6qaq+qv51+jazP4+7quqcxbM+vKqemlVfTTJPyR5R1W9Z/5z7LiDffy6rG2939vn7fMbZE3u+Ga+vWOcxbIc4yyWta33e/u8fX6DrEke36z5uP813/9PTHJlkt+uql/f0hDdPZklySVJfjrJPdasu8d83esWzDp7k+VBSd63QM6rkzwzyXck2Tu/f4f5Y1cuONOfJ3likqcmuXr+eZ0yX/dnC2Z9NslN65ZPz/+8ccGsK9fc/p0kv5jktCRPSvKnC2Zds+b2pUkePL993ySXL5h1U5JfS/KeJG+dz/PlW9y33prkvCR7krw3yXfN15+T5G8WzPqzJI9NsivJTyb5L0nOSPKSJL+0YNbfJPneJMeuWXdsksckefOCWY/eZPnOJLcumPX6JP8hyb9N8twkb0py0vyxqxbM+ssk3z7/2t88/9xqvu4NW9jv3zTft/Yv/zL/8y8OYb+/KMmFmRWr/34Lc63d79+U5PT57ZOTvH3BrOuTPCHJXye5Jcmzk3ztFvf7tyV5QJKvS/LB/TnzdYv+/PqLJA9fs6/9RpI7zX9evMh+b5+3zx8wa3LHN/Msxzhb3+8d4xzl+7193j6/QdYkj2/WZF41//P/SPJf57ev3lLWVj7ocC1Jrt/KY5ts/5nMDgAu3WD5lwVy3rbu/s9mdqBz0iI/aNZ+4+a333Og5xnIevL8h9dXrVl30xa/7lduNscW5rouyY757Teve+yaQ5jrG5I8P8n759/DC5f4tV/0P8VvX3f/svmfxyR514JZ797KY5ts/+kkv5/kxRssH18wa/1+8P1Jrk1yn0Pc72/Y7Hs8mPWdSf7fJOetWXfTIhmb7F/rP99F94lrk5wwv/1XSY5Z+9ghzHVqkp/KrC2+MYv/Y7Y2670H+h4PZK3f769Yc9t+v8n+Y5+3z8+3n9zxzSb7gWOcA2c5xlksa1vv9/Z5+/wGWZM8vln7PUtyzySvy+cLoS2VCDsyLTdX1U8leUl3/32SzE+7eWxmLdMirkvy+O5+9/oHqmqRrDtU1THd/dkk6e7/VlW3ZPabpjsvONPal4+89ACPHVR3/19V9aokvzH/fJ6epBecZ7+7V9VPZvabshOqqnq+Vy06V2Y/EC6uqmcm+fOqenaSP07yTZn9hmhLuvuNSd5YVU9M8qjMWr4XLRDxiar65iRfmqSr6ju6+0/np2J9ZsFx/qmqHtbdf1VV5yf50HzGz1YtfCruFfNT516Sz+/jpyT5wSRXLZh1dZJf6+53rH+gqh65YNZxVXXH7v5EknT3y6rq/Zn9VuFOC2Ydu+b2+lOmjl8kqLtfXVWXJPmFmp2a/eRsfb/fVVXPyWy/31lVx3X3p+ePLXSqcpL/muTSqnpeZgcif1hVe5M8IrODgkV8bh/q7vckeVaSZ1XV/TPb7xfxkap6fJITkny4qp6U2W+gH5nkHxfMurWqvj+zf+wfneTvkmS+zy/6c2K77/f2+cUcDfv8FI9vEsc4jnG+2DKPcbb7fm+f36JtvM9P9fhmv2dkdkzzV919WVV9RZIv+js1ZCvNw+Faktwts9dUvivJh+fLdfN1Jy6Y9V1J7rfJY9+xQM6zkjxyg/XnZvFG6RlJ7rzB+q9M8keH8HW7IMmbk7x/ix//9HXLzvn6eyR56RbyHpHkVZn9ZbkmyWuTPD7JcQvmvHKJ+9ZXz//SvDbJ/TM7XfYjmf027esXzHpgZqdRfSSz38Ddb75+Z5IfXzDr+CT/MbOD7mvWfL1+NPNT6xbI+oYkp27y2O4Fs56U5Bs3WH9WktcvmPX4A+z3//0QvqdnZXZw/4EtfvwPrlvuNl9/jyz42881n8+vJPmTJP8jyQuSfMsWcn59q1+TDbJOSfLC+Sz3mH9f35HkNUkesGDWqZn9Z+wdSV6W5J7z9Scl+c4Fs7b1fm+ft89vkLX2+OZD82Wlxzfz7Y+EY5zz4xjnYFlTPcbZ1vv9UbTPP3yDff7CbbjPf3i+z993vn5Zx/V/nhUf3xyOpeaDcISrqi9Jcp/eoK2C7WreEN+luz+26lng9mCf52jkGIejjX2ew6GqXpwNznDp7h/eYPMDmtS7MySzqzzX7Eqne+fLC2rNVUZXkTXFmdZnZdYQ/tjU5joCsr5l1XMd4DmeJuvAeuZjy8haS9bhz5r/HXpcVZ22bv3C/5CtyTp9KlmHa6Z1+/xUvlbb8nu4LuuQPsea+Z6q+u757XOq6jlV9aNVtdCx2NGYleTrk1w4tbmOgKz/eAhZ33Woc22S/xeHmjHlrGXldPe/JHnOMrKSaX6ttmNWrXtL4ar6/vnfnwvnP8tWkrXG/8zszLzXJHlDZi/9W/SlfrN5pnQmQlX998yu9vnSJPvmq3cl+YHMTi/6ids7a4ozydo+WQd5nvd096myZG23rKr6pSQPy+zied+e2Sn+z50/dmV3D7914ZKzfjnJQw81a1k5U/38jqK5lpn1/CR3z+xU148luUNmV4X/tiR/v+C/QbJkHSlZV69fldnx0/VJ0t3D71E/xazbYaYzkvztkrK2zdd94lmf+7ehqn4us5ckvDzJv0uyr7uftIqsAzzHMZldH+HrF/7gVb+eYu2S5G83WV9Z/LV5S8ma4kyytlXWxzZZPp7kNlmytmnWNfn81Z7vmuTiJL8xv7/oVZUnlzXFmWStPmv+53GZvfXk8fP7O7LglbFlyTqCsvZmdj2R+2f2FoOnZ3axudOSnHakZ01xJlkrz1r7rhFXJrlTf/7v06LvZrG0rAM8x/2y7l2kRpepvZzhE1X14A3WPzjJJ1aUNcWZZG2frI8kOaO7T1i33CXJ+2TJ2qZZO7r7tiTp7o9k9lveE6rqD7PguxdMNGuKM8labdb+nE9n9vZhn5rfvy2z94eXJWvbZXX3+UlendlV97+6u/8uyae7++buvvlIz5riTLJWm5XkS6rqrKp6UJJju/uf5s/x6Sz+rhHLzEqSVNXHq+pj+5fMLor801vJmlqJ8Ngkv1lV76yq182X6zJ7TdBjV5Q1xZlkbZ+sl2bWdG7k5bJkbdOs/69mb8OUJOnuz3T34zI7dfAB2yBrijPJWm3W+6vqzvOcz10/p6rukeRTsmRt06x0958kOS/Jw6vqz7J4ATfprCnOJGulWe/L7K2dfy3Jh6rqnklSVSdlXtCtKCtJ0t136S/8RdB9u/vVW8k65NMgDseS2VuQPGi+3GODx//17Z01xZlkbZ+sgeeSJWvbZCX5kiRfsslj9zrSs6Y4k6zVZh3gOe6U5O6yZB0NWZm9Ld9/2GD9tsia4kyyVpu15mOPTfKvVp2V5A0j64aytvoJrHJJcuXUsqY4kyxZsmTJmm7WFGeSJUuWLFnLzZriTLKOrqwkd0xyYpK3J7nb/PaJmV3/4V1bed4dOTJt9W0tDmfWFGeSJUuWLFnTzZriTLJkyZIla7lZU5xJ1tGV9fgk/2eSL09yxZqP+ViS39zKkx6pJUJPMGuKM8mSJUuWrOlmTXEmWbJkyZK13KwpziTrKMrq7mcneXZVPbHnb1V8qI7UEgEAAAAY0N3Prap/k+TMzF7isH/9SxfNmtq7M6RmTjnIZkNXh11W1hRnkiVLlixZ082a4kyyZMmSJWu5WVOcSZasA+Q9Pclz58sjkjwryfmjH/8FWfOLLUxKVV3T3V81pawpziRLlixZsqabNcWZZMmSJUvWcrOmOJMsWZtlZfbuE1d191dX1ZcleVl3P2rRrMmdiTB3ZfFwstUAAAmMSURBVFU9eGJZU5xJlixZsmRNN2uKM8mSJUuWrOVmTXEmWbI28i/d/dkkt1XVCUk+kORgZzpsaKpnIrwryVcmuTnJP2V2Bcnu7geuKmuKM8mSJUuWrOlmTXEmWbJkyZK13KwpziRL1iZZz0/yn5M8JsmTk/xjkrd19w8tnDXREuG0jdZ3982rypriTLJkyZIla7pZU5xJlixZsmQtN2uKM8mSNZB7epITuvvqLX38FEuEJKmqr07yDfO7b+zut686a4ozyZIlS5as6WZNcSZZsmTJkrXcrCnOJEvWBjlv6O5zDrZuxCSviVBVP5Hk/05y9/nysqp64iqzpjiTLFmyZMmabtYUZ5IlS5YsWcvNmuJMsmSty7hjVZ2Y5OSqultVnThfTk9yr63Mle6e3JLk6iR3WnP/TkmuXmXWFGeSJUuWLFnTzZriTLJkyZIla7lZU5xJlqx1GT+R5KYkn0xy4/z2TUnenuQJW5lrR6apknxmzf3PzNetMmuKM8mSJUuWrOlmTXEmWbJkyZK13KwpziRL1ud097OTPLuqntjdz93iHF9gqiXCi5O8par+JLMv0gVJfnfFWVOcSZYsWbJkTTdrijPJkiVLlqzlZk1xJlmyNvL+qrpLd3+8qn4uydlJfrG7r1w0aMoXVjw7ycPmd9/Y3VetOmuKM8mSJUuWrOlmTXEmWbJkyZK13KwpziRL1gY5V3f3A6vqYUl+McmvJnlad3/NwmFbeQ3E4V6S3CfJHea3H5Hkx5PcdZVZU5xJlixZsmRNN2uKM8mSJUuWrOVmTXEmWbI2ybpq/ucvJ/m+tesWXSb57gxJXp3kM1X1lUl+K8kpSV6+4qwpziRLlixZsqabNcWZZMmSJUvWcrOmOJMsWRu5papemOR7k1xcVXfIFt+tcaolwme7+7Ykj07ym939lCT3XHHWFGeSJUuWLFnTzZriTLJkyZIla7lZU5xJlqyNfE+SS5J8S3d/JMmJSZ6y/8Gqutto0FRLhE9X1Z4kP5Dkf87XHbfirCnOJEuWLFmypps1xZlkyZIlS9Zys6Y4kyxZX6S7/7m7/7i73z2//77uft2aTd6wSNjkliRnJnlOkj3z+/dO8tOrzJriTLJkyZIla7pZU5xJlixZsmQtN2uKM8mStcXnGr4+wmTfnQEAAAA4/Krqyu4+e2TbHYd7mK2oqocm+fkkp2U2YyXp7v6KVWVNcSZZsmTJkjXdrCnOJEuWLFmylps1xZlkyTrcJnkmQlW9K8mTklyR5DP713f3B1eVNcWZZMmSJUvWdLOmOJMsWbJkyVpu1hRnkiVrK6rqqu4+a2TbSZ6JkOSj3f3aiWVNcSZZsmTJkjXdrCnOJEuWLFmylps1xZlkydpQVT0syRnd/eKq2pnkzt190/zhc4ZzJnomwjOTHJvkj5N8cv/67r5yVVlTnEmWLFmyZE03a4ozyZIlS5as5WZNcSZZsjbJenqS3Unu1933raovT/KH3f3QhbMmWiJcusHq7u5vWlXWFGeSJUuWLFnTzZriTLJkyZIla7lZU5xJlqxNst6W5KwkV/b8ZQtVdXV3P3DhrCmWCAAAAMByVNVbu/shNX8Xhqq6U5K/2UqJcMxhmO+QVdWXVdXvVtVr5/fPrKrHrTJrijPJkiVLlqzpZk1xJlmyZMmStdysKc4kS9YmLqqqFya5a1X9SJL/J8lvbympuye3JHltku9J8vb5/R1Jrlll1hRnkiVLlixZ082a4kyyZMmSJWu5WVOcSZasA+Q9KsmvJvm1JI/aas4kz0RIcnJ3X5Tks0nS3bdlzVtarChrijPJkiVLlqzpZk1xJlmyZMmStdysKc4kS9aGuvv13f2U7v5P3f36reZMtUT4p6o6KUknSVV9bZKPrjhrijPJkiVLlqzpZk1xJlmyZMmStdysKc4kS9YXqapHV9W7q+qjVfWxqvp4VX1sS1Nt9RSGw7kkOTvJX8+/QH+d5G+TPHCVWVOcSZYsWbJkTTdrijPJkiVLlqzlZk1xJlmyNsm6IckDtvKx65epnolwnyTnJfn6JJckeXdmr/9YZdYUZ5IlS5YsWdPNmuJMsmTJkiVruVlTnEmWrI38fXdft8WP/ULLaCKWvSS5ev7nw5JcmuTbkrxllVlTnEmWLFmyZE03a4ozyZIlS5as5WZNcSZZsjbJenaSVyXZk+TR+5etZE31TIT9F4v4tiS/3d2vSXL8irOmOJMsWbJkyZpu1hRnkiVLlixZy82a4kyyZG3khCT/nOSbk3z7fPl3Wwmaaolwy/w9LL83ycVVdYdsfdZlZU1xJlmyZMmSNd2sKc4kS5YsWbKWmzXFmWTJ+iLd/UMbLD+8pam2cvrC4V6S/KvMTq84Y37/nkm+eZVZU5xJlixZsmRNN2uKM8mSJUuWrOVmTXEmWbLWZfzU/M/nJnnO+mUrc9U8EAAAANhGqurbu/t/VNUPbvR4d79k4UwlAgAAADBiq28PAQAAABwBquq+Sf5TktOzpgfo7m9aOMuZCAAAALB9VdXbk/xWkivy+Xd9SHdfsXCWEgEAAAC2r6q6orsftJQsJQIAAABsP1V14vzmjyf5QJI/SfLJ/Y9394cWzlQiAAAAwPZTVTcl6SS1wcPd3V+xcKYSAQAAABhxzKoHAAAAAA6fqvqxqrrrmvt3q6of3VKWMxEAAABg+6qqt3X3v1237qruPmvRLGciAAAAwPZ2bFV97roIVXVskuO3ErRjaSMBAAAAU/TnSV5VVS+c33/8fN3CvJwBAAAAtrGqOiaz4uCc+arXJ/md7v7MwllKBAAAAGCElzMAAADANlZVZyT55SRnJrnj/vXd/RWLZrmwIgAAAGxvL07ygiS3JXlEkpcmedlWgrycAQAAALaxqrqiux9UVdd091etXbdolpczAAAAwPb2yfnFFd9dVU9IckuSO28lyJkIAAAAsI1V1YOTXJfkrkl+IckJSZ7V3W9ZOEuJAAAAANtXVe1O8rNJTkty3Hx1d/cDF85SIgAAAMD2VVXXJ3lKkmuSfHb/+u6+edEs10QAAACA7e3W7t67jCBnIgAAAMA2VlXnJNmT5A1JPrl/fXf/8aJZzkQAAACA7e2Hktw/s+sh7H85QydZuERwJgIAAABsY1V1fXffbxlZxywjBAAAAJisN1XVmcsIciYCAAAAbGNVdV2S+yS5KbNrIlS8xSMAAACwXlWdttH6rbzFoxIBAAAAGOKaCAAAAMAQJQIAAAAwRIkAAAAADFEiAAAAAEOUCAAAAMCQ/w0y6usNt7j/zgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 1296x576 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# data preprocessing\n",
        "\n",
        "# change data type (timestamp to datetime / for sensor to numeric)\n",
        "for var_index in [item for item in df.columns if 'sensor_' in item]:\n",
        "  df[var_index] = pd.to_numeric(df[var_index], errors = 'coerce')\n",
        "\n",
        "del df['timestamp']\n",
        "\n",
        "# find Null\n",
        "(df.isnull().sum()/len(df)).plot.bar(figsize=(18, 8), colormap='Paired')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "6YC8P_KD4LNg",
        "outputId": "8f86efae-8286-4ae8-b717-ad70354017a6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-687c8f1e-cc28-4136-bff7-2abfc18802a5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sensor_00</th>\n",
              "      <th>sensor_01</th>\n",
              "      <th>sensor_02</th>\n",
              "      <th>sensor_03</th>\n",
              "      <th>sensor_04</th>\n",
              "      <th>sensor_05</th>\n",
              "      <th>sensor_06</th>\n",
              "      <th>sensor_07</th>\n",
              "      <th>sensor_08</th>\n",
              "      <th>sensor_09</th>\n",
              "      <th>...</th>\n",
              "      <th>sensor_42</th>\n",
              "      <th>sensor_43</th>\n",
              "      <th>sensor_44</th>\n",
              "      <th>sensor_45</th>\n",
              "      <th>sensor_46</th>\n",
              "      <th>sensor_47</th>\n",
              "      <th>sensor_48</th>\n",
              "      <th>sensor_49</th>\n",
              "      <th>sensor_51</th>\n",
              "      <th>machine_status</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.465394</td>\n",
              "      <td>47.09201</td>\n",
              "      <td>53.211800</td>\n",
              "      <td>46.310760</td>\n",
              "      <td>634.375000</td>\n",
              "      <td>76.45975</td>\n",
              "      <td>13.41146</td>\n",
              "      <td>16.13136</td>\n",
              "      <td>15.56713</td>\n",
              "      <td>15.05353</td>\n",
              "      <td>...</td>\n",
              "      <td>31.770832</td>\n",
              "      <td>41.92708</td>\n",
              "      <td>39.641200</td>\n",
              "      <td>65.68287</td>\n",
              "      <td>50.92593</td>\n",
              "      <td>38.194440</td>\n",
              "      <td>157.9861</td>\n",
              "      <td>67.70834</td>\n",
              "      <td>201.3889</td>\n",
              "      <td>NORMAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.444734</td>\n",
              "      <td>47.35243</td>\n",
              "      <td>53.211800</td>\n",
              "      <td>46.397570</td>\n",
              "      <td>638.888900</td>\n",
              "      <td>73.54598</td>\n",
              "      <td>13.32465</td>\n",
              "      <td>16.03733</td>\n",
              "      <td>15.61777</td>\n",
              "      <td>15.01013</td>\n",
              "      <td>...</td>\n",
              "      <td>31.770830</td>\n",
              "      <td>41.66666</td>\n",
              "      <td>39.351852</td>\n",
              "      <td>65.39352</td>\n",
              "      <td>51.21528</td>\n",
              "      <td>38.194443</td>\n",
              "      <td>155.9606</td>\n",
              "      <td>67.12963</td>\n",
              "      <td>203.7037</td>\n",
              "      <td>NORMAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.460474</td>\n",
              "      <td>47.09201</td>\n",
              "      <td>53.168400</td>\n",
              "      <td>46.397568</td>\n",
              "      <td>628.125000</td>\n",
              "      <td>76.98898</td>\n",
              "      <td>13.31742</td>\n",
              "      <td>16.24711</td>\n",
              "      <td>15.69734</td>\n",
              "      <td>15.08247</td>\n",
              "      <td>...</td>\n",
              "      <td>31.510420</td>\n",
              "      <td>40.88541</td>\n",
              "      <td>39.062500</td>\n",
              "      <td>64.81481</td>\n",
              "      <td>51.21528</td>\n",
              "      <td>38.194440</td>\n",
              "      <td>155.9606</td>\n",
              "      <td>66.84028</td>\n",
              "      <td>203.1250</td>\n",
              "      <td>NORMAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.445718</td>\n",
              "      <td>47.13541</td>\n",
              "      <td>53.211800</td>\n",
              "      <td>46.397568</td>\n",
              "      <td>636.458300</td>\n",
              "      <td>76.58897</td>\n",
              "      <td>13.35359</td>\n",
              "      <td>16.21094</td>\n",
              "      <td>15.69734</td>\n",
              "      <td>15.08247</td>\n",
              "      <td>...</td>\n",
              "      <td>31.510420</td>\n",
              "      <td>41.40625</td>\n",
              "      <td>38.773150</td>\n",
              "      <td>65.10416</td>\n",
              "      <td>51.79398</td>\n",
              "      <td>38.773150</td>\n",
              "      <td>158.2755</td>\n",
              "      <td>66.55093</td>\n",
              "      <td>201.3889</td>\n",
              "      <td>NORMAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2.453588</td>\n",
              "      <td>47.09201</td>\n",
              "      <td>53.168400</td>\n",
              "      <td>46.397568</td>\n",
              "      <td>637.615700</td>\n",
              "      <td>78.18568</td>\n",
              "      <td>13.41146</td>\n",
              "      <td>16.16753</td>\n",
              "      <td>15.89265</td>\n",
              "      <td>15.16204</td>\n",
              "      <td>...</td>\n",
              "      <td>31.250000</td>\n",
              "      <td>42.70833</td>\n",
              "      <td>38.773150</td>\n",
              "      <td>63.65741</td>\n",
              "      <td>51.79398</td>\n",
              "      <td>38.773150</td>\n",
              "      <td>164.6412</td>\n",
              "      <td>66.55093</td>\n",
              "      <td>201.6782</td>\n",
              "      <td>NORMAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>220315</th>\n",
              "      <td>2.407350</td>\n",
              "      <td>47.69965</td>\n",
              "      <td>50.520830</td>\n",
              "      <td>43.142361</td>\n",
              "      <td>634.722229</td>\n",
              "      <td>64.59095</td>\n",
              "      <td>15.11863</td>\n",
              "      <td>16.65220</td>\n",
              "      <td>15.65393</td>\n",
              "      <td>15.16204</td>\n",
              "      <td>...</td>\n",
              "      <td>30.208330</td>\n",
              "      <td>38.28125</td>\n",
              "      <td>68.287030</td>\n",
              "      <td>52.37268</td>\n",
              "      <td>48.32176</td>\n",
              "      <td>41.087960</td>\n",
              "      <td>212.3843</td>\n",
              "      <td>153.64580</td>\n",
              "      <td>231.1921</td>\n",
              "      <td>NORMAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>220316</th>\n",
              "      <td>2.400463</td>\n",
              "      <td>47.69965</td>\n",
              "      <td>50.564240</td>\n",
              "      <td>43.142361</td>\n",
              "      <td>630.902771</td>\n",
              "      <td>65.83363</td>\n",
              "      <td>15.15480</td>\n",
              "      <td>16.70284</td>\n",
              "      <td>15.65393</td>\n",
              "      <td>15.11863</td>\n",
              "      <td>...</td>\n",
              "      <td>29.947920</td>\n",
              "      <td>38.28125</td>\n",
              "      <td>66.840280</td>\n",
              "      <td>50.63657</td>\n",
              "      <td>48.03241</td>\n",
              "      <td>40.798610</td>\n",
              "      <td>213.8310</td>\n",
              "      <td>156.25000</td>\n",
              "      <td>231.1921</td>\n",
              "      <td>NORMAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>220317</th>\n",
              "      <td>2.396528</td>\n",
              "      <td>47.69965</td>\n",
              "      <td>50.520830</td>\n",
              "      <td>43.142361</td>\n",
              "      <td>625.925903</td>\n",
              "      <td>67.29445</td>\n",
              "      <td>15.08970</td>\n",
              "      <td>16.70284</td>\n",
              "      <td>15.69734</td>\n",
              "      <td>15.11863</td>\n",
              "      <td>...</td>\n",
              "      <td>30.208330</td>\n",
              "      <td>39.06250</td>\n",
              "      <td>65.393520</td>\n",
              "      <td>48.90046</td>\n",
              "      <td>48.03241</td>\n",
              "      <td>40.798610</td>\n",
              "      <td>217.3032</td>\n",
              "      <td>155.38190</td>\n",
              "      <td>232.0602</td>\n",
              "      <td>NORMAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>220318</th>\n",
              "      <td>2.406366</td>\n",
              "      <td>47.69965</td>\n",
              "      <td>50.520832</td>\n",
              "      <td>43.142361</td>\n",
              "      <td>635.648100</td>\n",
              "      <td>65.09175</td>\n",
              "      <td>15.11863</td>\n",
              "      <td>16.56539</td>\n",
              "      <td>15.74074</td>\n",
              "      <td>15.11863</td>\n",
              "      <td>...</td>\n",
              "      <td>30.208332</td>\n",
              "      <td>40.62500</td>\n",
              "      <td>64.236110</td>\n",
              "      <td>47.74306</td>\n",
              "      <td>48.32176</td>\n",
              "      <td>40.509258</td>\n",
              "      <td>222.5116</td>\n",
              "      <td>153.93520</td>\n",
              "      <td>234.0856</td>\n",
              "      <td>NORMAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>220319</th>\n",
              "      <td>2.396528</td>\n",
              "      <td>47.69965</td>\n",
              "      <td>50.520832</td>\n",
              "      <td>43.142361</td>\n",
              "      <td>639.814800</td>\n",
              "      <td>65.45634</td>\n",
              "      <td>15.11863</td>\n",
              "      <td>16.65220</td>\n",
              "      <td>15.65393</td>\n",
              "      <td>15.01013</td>\n",
              "      <td>...</td>\n",
              "      <td>30.208332</td>\n",
              "      <td>41.40625</td>\n",
              "      <td>62.789350</td>\n",
              "      <td>46.29630</td>\n",
              "      <td>48.90046</td>\n",
              "      <td>40.219910</td>\n",
              "      <td>227.4306</td>\n",
              "      <td>150.46300</td>\n",
              "      <td>234.0856</td>\n",
              "      <td>NORMAL</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>217444 rows Ã— 51 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-687c8f1e-cc28-4136-bff7-2abfc18802a5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-687c8f1e-cc28-4136-bff7-2abfc18802a5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-687c8f1e-cc28-4136-bff7-2abfc18802a5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        sensor_00  sensor_01  sensor_02  sensor_03   sensor_04  sensor_05  \\\n",
              "0        2.465394   47.09201  53.211800  46.310760  634.375000   76.45975   \n",
              "2        2.444734   47.35243  53.211800  46.397570  638.888900   73.54598   \n",
              "3        2.460474   47.09201  53.168400  46.397568  628.125000   76.98898   \n",
              "4        2.445718   47.13541  53.211800  46.397568  636.458300   76.58897   \n",
              "5        2.453588   47.09201  53.168400  46.397568  637.615700   78.18568   \n",
              "...           ...        ...        ...        ...         ...        ...   \n",
              "220315   2.407350   47.69965  50.520830  43.142361  634.722229   64.59095   \n",
              "220316   2.400463   47.69965  50.564240  43.142361  630.902771   65.83363   \n",
              "220317   2.396528   47.69965  50.520830  43.142361  625.925903   67.29445   \n",
              "220318   2.406366   47.69965  50.520832  43.142361  635.648100   65.09175   \n",
              "220319   2.396528   47.69965  50.520832  43.142361  639.814800   65.45634   \n",
              "\n",
              "        sensor_06  sensor_07  sensor_08  sensor_09  ...  sensor_42  sensor_43  \\\n",
              "0        13.41146   16.13136   15.56713   15.05353  ...  31.770832   41.92708   \n",
              "2        13.32465   16.03733   15.61777   15.01013  ...  31.770830   41.66666   \n",
              "3        13.31742   16.24711   15.69734   15.08247  ...  31.510420   40.88541   \n",
              "4        13.35359   16.21094   15.69734   15.08247  ...  31.510420   41.40625   \n",
              "5        13.41146   16.16753   15.89265   15.16204  ...  31.250000   42.70833   \n",
              "...           ...        ...        ...        ...  ...        ...        ...   \n",
              "220315   15.11863   16.65220   15.65393   15.16204  ...  30.208330   38.28125   \n",
              "220316   15.15480   16.70284   15.65393   15.11863  ...  29.947920   38.28125   \n",
              "220317   15.08970   16.70284   15.69734   15.11863  ...  30.208330   39.06250   \n",
              "220318   15.11863   16.56539   15.74074   15.11863  ...  30.208332   40.62500   \n",
              "220319   15.11863   16.65220   15.65393   15.01013  ...  30.208332   41.40625   \n",
              "\n",
              "        sensor_44  sensor_45  sensor_46  sensor_47  sensor_48  sensor_49  \\\n",
              "0       39.641200   65.68287   50.92593  38.194440   157.9861   67.70834   \n",
              "2       39.351852   65.39352   51.21528  38.194443   155.9606   67.12963   \n",
              "3       39.062500   64.81481   51.21528  38.194440   155.9606   66.84028   \n",
              "4       38.773150   65.10416   51.79398  38.773150   158.2755   66.55093   \n",
              "5       38.773150   63.65741   51.79398  38.773150   164.6412   66.55093   \n",
              "...           ...        ...        ...        ...        ...        ...   \n",
              "220315  68.287030   52.37268   48.32176  41.087960   212.3843  153.64580   \n",
              "220316  66.840280   50.63657   48.03241  40.798610   213.8310  156.25000   \n",
              "220317  65.393520   48.90046   48.03241  40.798610   217.3032  155.38190   \n",
              "220318  64.236110   47.74306   48.32176  40.509258   222.5116  153.93520   \n",
              "220319  62.789350   46.29630   48.90046  40.219910   227.4306  150.46300   \n",
              "\n",
              "        sensor_51  machine_status  \n",
              "0        201.3889          NORMAL  \n",
              "2        203.7037          NORMAL  \n",
              "3        203.1250          NORMAL  \n",
              "4        201.3889          NORMAL  \n",
              "5        201.6782          NORMAL  \n",
              "...           ...             ...  \n",
              "220315   231.1921          NORMAL  \n",
              "220316   231.1921          NORMAL  \n",
              "220317   232.0602          NORMAL  \n",
              "220318   234.0856          NORMAL  \n",
              "220319   234.0856          NORMAL  \n",
              "\n",
              "[217444 rows x 51 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# since sensor 15 is all null, sensor 50 is 50% null, delete\n",
        "# other sensors with null, use previous time's data for null\n",
        "\n",
        "# delete duplicates\n",
        "df = df.drop_duplicates()\n",
        "\n",
        "# delete sensor 15, 50\n",
        "del df['sensor_15']\n",
        "del df['sensor_50']\n",
        "\n",
        "# fill null for previous data\n",
        "df = df.fillna(method = 'ffill')\n",
        "df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3RIWBnT4N_C",
        "outputId": "63d91108-807f-44f4-9aed-053666422f8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "False\n"
          ]
        }
      ],
      "source": [
        "check_for_nan = df.isnull().values.any()\n",
        "print (check_for_nan)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7a4TAHvk4P25",
        "outputId": "381e3ba4-ec22-4c7a-ed8c-b681bfceaa2e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0         1\n",
              "2         1\n",
              "3         1\n",
              "4         1\n",
              "5         1\n",
              "         ..\n",
              "220315    1\n",
              "220316    1\n",
              "220317    1\n",
              "220318    1\n",
              "220319    1\n",
              "Name: machine_status, Length: 217444, dtype: int64"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Status = { \"NORMAL\": 1, \"BROKEN\": 0, \"RECOVERING\":0}\n",
        "state = df[\"machine_status\"].replace(Status)\n",
        "df['machine_status']=state\n",
        "\n",
        "df['machine_status']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "coNSHO_H4QwC"
      },
      "outputs": [],
      "source": [
        "# x, y\n",
        "input_x = df.drop('machine_status', axis=1).values\n",
        "input_y = df['machine_status'].values\n",
        "\n",
        "n_features = input_x.shape[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X9gAt2DA4Sna"
      },
      "outputs": [],
      "source": [
        "def temporalize(X, y, timesteps):\n",
        "\toutput_X = []\n",
        "\toutput_y = []\n",
        "\tfor i in range(len(X) - timesteps - 1):\n",
        "\t\tt = []\n",
        "\t\tfor j in range(1, timesteps + 1):\n",
        "\t\t\t# Gather the past records upto the lookback period\n",
        "\t\t\tt.append(X[[(i + j + 1)], :])\n",
        "\t\toutput_X.append(t)\n",
        "\t\toutput_y.append(y[i + timesteps + 1])\n",
        "\treturn np.squeeze(np.array(output_X)), np.array(output_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rotisYz4UMe",
        "outputId": "88e94d33-1e13-4f80-b5d1-99054db31eff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(217438, 5, 50)\n"
          ]
        }
      ],
      "source": [
        "timesteps = 5 # 5min timestep \n",
        "# Temporalize\n",
        "x, y = temporalize(input_x, input_y, timesteps)\n",
        "print(x.shape) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVHumnAe4YF6",
        "outputId": "9acc3d86-36f7-4f6f-b89f-9a038e9495dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "139160\n",
            "34790\n",
            "43488\n"
          ]
        }
      ],
      "source": [
        "# Split into train, valid, and test \n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
        "x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.2)\n",
        "\n",
        "print(len(x_train))  \n",
        "print(len(x_valid))  \n",
        "print(len(x_test))   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GL_jWEc84ann",
        "outputId": "a610bbd1-cdc8-4967-9227-18ad417fa2e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(9164, 5, 50)\n"
          ]
        }
      ],
      "source": [
        "# For training the autoencoder, split 0 / 1\n",
        "# training only by normal data\n",
        "x_train_y0 = x_train[y_train == 0]\n",
        "x_train_y1 = x_train[y_train == 1]\n",
        "\n",
        "x_valid_y0 = x_valid[y_valid == 0]\n",
        "x_valid_y1 = x_valid[y_valid == 1]\n",
        "print(x_train_y0.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dp3P6r3Y4c1_"
      },
      "outputs": [],
      "source": [
        "# LSTMì€ 3D data, ScalerëŠ” 2D data\n",
        "def flatten(X):\n",
        "    flattened_X = np.empty((X.shape[0], X.shape[2]))  # sample x features array.\n",
        "    for i in range(X.shape[0]):\n",
        "        flattened_X[i] = X[i, (X.shape[1]-1), :]\n",
        "    return(flattened_X)\n",
        "\n",
        "def scale(X, scaler):\n",
        "    for i in range(X.shape[0]):\n",
        "        X[i, :, :] = scaler.transform(X[i, :, :])\n",
        "        \n",
        "    return X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2vcsj0zH4fA5"
      },
      "outputs": [],
      "source": [
        "# ë°ì´í„°ê°€ íŽ¸í–¥ë˜ëŠ” ê²ƒì„ ë§‰ê¸° ìœ„í•´ standardize\n",
        "scaler = StandardScaler().fit(flatten(x_train_y1))\n",
        "\n",
        "x_train_y1_scaled = scale(x_train_y1, scaler)\n",
        "x_valid_scaled = scale(x_valid, scaler)\n",
        "x_valid_y1_scaled = scale(x_valid_y1, scaler)\n",
        "x_test_scaled = scale(x_test, scaler)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjbGx5l2DDy2"
      },
      "source": [
        "[2] Model\n",
        "- LSTM autoencoder\n",
        "- sequence dataë¥¼ íš¨ê³¼ì ìœ¼ë¡œ í•™ìŠµ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sPjoxUWj4gLl"
      },
      "outputs": [],
      "source": [
        "# build model\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, seq_len, n_features, embedding_dim=64):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.seq_len, self.n_features = seq_len, n_features\n",
        "        self.embedding_dim, self.hidden_dim = (\n",
        "            embedding_dim, 2 * embedding_dim\n",
        "        )\n",
        "        self.rnn1 = nn.LSTM(\n",
        "          input_size=n_features,\n",
        "          hidden_size=self.hidden_dim,\n",
        "          num_layers=1,\n",
        "          batch_first=True\n",
        "        )\n",
        "        self.rnn2 = nn.LSTM(\n",
        "          input_size=self.hidden_dim,\n",
        "          hidden_size=embedding_dim,\n",
        "          num_layers=1,\n",
        "          batch_first=True\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        x, (_, _) = self.rnn1(x)\n",
        "        x, (hidden_n, _) = self.rnn2(x)\n",
        "        return  x[:,-1,:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i3-OSc3l4nDC"
      },
      "outputs": [],
      "source": [
        "class TimeDistributed(nn.Module):\n",
        "    def __init__(self, module, batch_first=False):\n",
        "        super(TimeDistributed, self).__init__()\n",
        "        self.module = module\n",
        "        self.batch_first = batch_first\n",
        "\n",
        "    def forward(self, x):\n",
        "        if len(x.size()) <= 2:\n",
        "            return self.module(x)\n",
        "        # Squash samples and timesteps into a single axis\n",
        "        x_reshape = x.contiguous().view(-1, x.size(-1))  # (samples * timesteps, input_size)\n",
        "        y = self.module(x_reshape)\n",
        "        # We have to reshape Y\n",
        "        if self.batch_first:\n",
        "            y = y.contiguous().view(x.size(0), -1, y.size(-1))  # (samples, timesteps, output_size)\n",
        "        else:\n",
        "            y = y.view(-1, x.size(1), y.size(-1))  # (timesteps, samples, output_size)\n",
        "        return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RM3SH2R24pJL"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, seq_len, input_dim=64, n_features=1):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.seq_len, self.input_dim = seq_len, input_dim\n",
        "        self.hidden_dim, self.n_features = 2 * input_dim, n_features\n",
        "        self.rnn1 = nn.LSTM(\n",
        "          input_size=input_dim,\n",
        "          hidden_size=input_dim,\n",
        "          num_layers=1,\n",
        "          batch_first=True\n",
        "        )\n",
        "        self.rnn2 = nn.LSTM(\n",
        "          input_size=input_dim,\n",
        "          hidden_size=self.hidden_dim,\n",
        "          num_layers=1,\n",
        "          batch_first=True\n",
        "        )\n",
        "        self.output_layer = torch.nn.Linear(self.hidden_dim, n_features)\n",
        "        self.timedist = TimeDistributed(self.output_layer)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x=x.reshape(-1,1,self.input_dim).repeat(1,self.seq_len,1)       \n",
        "        x, (hidden_n, cell_n) = self.rnn1(x)\n",
        "        x, (hidden_n, cell_n) = self.rnn2(x)\n",
        "        return self.timedist(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IgZD_9VK4rwr"
      },
      "outputs": [],
      "source": [
        "class LSTM_ae(nn.Module):\n",
        "    def __init__(self, seq_len, n_features, embedding_dim=64):\n",
        "        super(LSTM_ae, self).__init__()\n",
        "        self.encoder = Encoder(seq_len, n_features, embedding_dim)#.to(device)\n",
        "        self.decoder = Decoder(seq_len, embedding_dim, n_features)#.to(device)\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.decoder(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iHcvxp_x4v1q"
      },
      "outputs": [],
      "source": [
        "model = LSTM_ae(timesteps, n_features, 128)\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C2mq_EXX4wlt"
      },
      "outputs": [],
      "source": [
        "class AutoencoderDataset(Dataset): \n",
        "    def __init__(self,x):\n",
        "        self.x = x\n",
        "    def __len__(self): \n",
        "        return len(self.x)\n",
        "    def __getitem__(self, idx): \n",
        "        x = torch.FloatTensor(self.x[idx,:,:])\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPCC_2UrDPB7"
      },
      "source": [
        "[3] Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gUFb71xb4ypi"
      },
      "outputs": [],
      "source": [
        "def train_model(model, train_dataset, val_dataset, n_epochs,batch_size):\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "    # L1 loss : LAD(Least Absolute Deciations), \n",
        "    # the absolute difference between a prediction and the actual value, calculated for each example in a dataset\n",
        "    criterion = nn.L1Loss(reduction='sum').to(device)\n",
        "    history = dict(train=[], val=[])\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_loss = 10000.0\n",
        "    print(\"start!\")\n",
        "    train_dataset_ae = AutoencoderDataset(train_dataset)\n",
        "    tr_dataloader = DataLoader(train_dataset_ae, batch_size=batch_size, \n",
        "                               shuffle=False,num_workers=8)\n",
        "    val_dataset_ae = AutoencoderDataset(val_dataset)\n",
        "    va_dataloader = DataLoader(val_dataset_ae, batch_size=len(val_dataset),\n",
        "                               shuffle=False,num_workers=8)\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        model = model.train()\n",
        "        train_losses = []\n",
        "        for batch_idx, batch_x in enumerate(tr_dataloader):\n",
        "            optimizer.zero_grad()\n",
        "            batch_x_tensor = batch_x.to(device)\n",
        "            seq_pred = model(batch_x_tensor)\n",
        "            loss = criterion(seq_pred, batch_x_tensor)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_losses.append(loss.item())\n",
        "        val_losses = []\n",
        "        model = model.eval()\n",
        "        with torch.no_grad():\n",
        "            va_x  =next(va_dataloader.__iter__())\n",
        "            va_x_tensor = va_x.to(device)\n",
        "            seq_pred = model(va_x_tensor)\n",
        "            loss = criterion(seq_pred, va_x_tensor)\n",
        "            val_losses.append(loss.item())\n",
        "        train_loss = np.mean(train_losses)\n",
        "        val_loss = np.mean(val_losses)\n",
        "        history['train'].append(train_loss)\n",
        "        history['val'].append(val_loss)\n",
        "        if val_loss < best_loss:\n",
        "            best_loss = val_loss\n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "        print(f'Epoch {epoch}: train loss {train_loss} val loss {val_loss}')\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model.eval(), history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXZjnRD541rm",
        "outputId": "19eae57c-3fa9-4f8c-ac70-624c73db847b"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "start!\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: train loss 2029.1754118699293 val loss 2955733.75\n",
            "Epoch 2: train loss 995.5709823608398 val loss 2292935.25\n",
            "Epoch 3: train loss 832.6947329477164 val loss 2052533.375\n",
            "Epoch 4: train loss 761.2287459388147 val loss 1900890.25\n",
            "Epoch 5: train loss 726.1264884127104 val loss 1841198.5\n",
            "Epoch 6: train loss 695.6290033663237 val loss 1750637.75\n",
            "Epoch 7: train loss 665.4485605093149 val loss 1694789.5\n",
            "Epoch 8: train loss 632.1542553710938 val loss 1617160.5\n",
            "Epoch 9: train loss 599.044689072829 val loss 1526384.875\n",
            "Epoch 10: train loss 577.7995986703726 val loss 1479250.875\n",
            "Epoch 11: train loss 560.8941808964656 val loss 1451192.25\n",
            "Epoch 12: train loss 546.600923990103 val loss 1406583.0\n",
            "Epoch 13: train loss 537.0457612844614 val loss 1381779.0\n",
            "Epoch 14: train loss 525.6595156977727 val loss 1351949.5\n",
            "Epoch 15: train loss 514.8408768169696 val loss 1328469.5\n",
            "Epoch 16: train loss 504.53394017146184 val loss 1309805.25\n",
            "Epoch 17: train loss 494.18340837918794 val loss 1274842.5\n",
            "Epoch 18: train loss 483.6855575444148 val loss 1263240.875\n",
            "Epoch 19: train loss 475.35311384934647 val loss 1229417.75\n",
            "Epoch 20: train loss 467.47887336144083 val loss 1206592.375\n",
            "Epoch 21: train loss 460.2904722360464 val loss 1183494.875\n",
            "Epoch 22: train loss 453.3381454702524 val loss 1173779.875\n",
            "Epoch 23: train loss 445.69683794461764 val loss 1148807.5\n",
            "Epoch 24: train loss 440.01737407977765 val loss 1148970.25\n",
            "Epoch 25: train loss 431.7032550518329 val loss 1127854.625\n",
            "Epoch 26: train loss 420.81121467003453 val loss 1093844.625\n",
            "Epoch 27: train loss 412.65779686560995 val loss 1078658.5\n",
            "Epoch 28: train loss 407.0280524151142 val loss 1072473.75\n",
            "Epoch 29: train loss 402.13859458336464 val loss 1051298.375\n",
            "Epoch 30: train loss 396.9019334881122 val loss 1037621.8125\n",
            "Epoch 31: train loss 392.03674069918117 val loss 1012749.0625\n",
            "Epoch 32: train loss 380.5985393113356 val loss 988831.125\n",
            "Epoch 33: train loss 373.3628476891151 val loss 974899.375\n",
            "Epoch 34: train loss 369.6357290297288 val loss 962381.6875\n",
            "Epoch 35: train loss 365.7288831622784 val loss 963233.125\n",
            "Epoch 36: train loss 362.8346026846079 val loss 936969.8125\n",
            "Epoch 37: train loss 359.60365009014424 val loss 935644.75\n",
            "Epoch 38: train loss 356.6830966421274 val loss 920452.0625\n",
            "Epoch 39: train loss 353.81670979426457 val loss 916059.125\n",
            "Epoch 40: train loss 350.4596535902757 val loss 907894.625\n",
            "Epoch 41: train loss 346.7654858985314 val loss 893144.625\n",
            "Epoch 42: train loss 344.4433561237042 val loss 898611.5625\n",
            "Epoch 43: train loss 342.22858002882737 val loss 888126.125\n",
            "Epoch 44: train loss 339.1412507864145 val loss 885488.8125\n",
            "Epoch 45: train loss 336.57864181518556 val loss 878950.0\n",
            "Epoch 46: train loss 334.50021085298977 val loss 874647.625\n",
            "Epoch 47: train loss 331.50786158635066 val loss 862131.5625\n",
            "Epoch 48: train loss 329.3629064002404 val loss 864854.375\n",
            "Epoch 49: train loss 325.85231681236854 val loss 852912.5\n",
            "Epoch 50: train loss 322.7771908334585 val loss 840036.75\n",
            "Epoch 51: train loss 320.21043264535757 val loss 838099.5\n",
            "Epoch 52: train loss 315.99990532508264 val loss 823818.1875\n",
            "Epoch 53: train loss 313.87152522160454 val loss 824707.375\n",
            "Epoch 54: train loss 311.0750331702599 val loss 804575.5625\n",
            "Epoch 55: train loss 309.4598970970741 val loss 807720.125\n",
            "Epoch 56: train loss 306.98108262282153 val loss 805277.0\n",
            "Epoch 57: train loss 306.10288946298454 val loss 803112.75\n",
            "Epoch 58: train loss 303.41985634436975 val loss 783180.75\n",
            "Epoch 59: train loss 301.1464204406738 val loss 785442.875\n",
            "Epoch 60: train loss 298.87850057161774 val loss 782444.375\n",
            "Epoch 61: train loss 296.60773209791915 val loss 776583.75\n",
            "Epoch 62: train loss 294.94155879680926 val loss 775516.125\n",
            "Epoch 63: train loss 293.1818479156494 val loss 763204.5625\n",
            "Epoch 64: train loss 291.5958325254 val loss 765708.625\n",
            "Epoch 65: train loss 291.01586218613846 val loss 753116.75\n",
            "Epoch 66: train loss 288.2372619394156 val loss 758724.4375\n",
            "Epoch 67: train loss 286.55458785423866 val loss 754056.875\n",
            "Epoch 68: train loss 284.78844492398775 val loss 741187.125\n",
            "Epoch 69: train loss 283.24207462604227 val loss 743145.5625\n",
            "Epoch 70: train loss 283.31114918048564 val loss 729513.5\n",
            "Epoch 71: train loss 279.8145560103196 val loss 741561.8125\n",
            "Epoch 72: train loss 279.1726466076191 val loss 725467.375\n",
            "Epoch 73: train loss 278.2208095902663 val loss 723571.5\n",
            "Epoch 74: train loss 277.2860826580341 val loss 717617.875\n",
            "Epoch 75: train loss 276.1585825876089 val loss 711008.875\n",
            "Epoch 76: train loss 274.9638747640756 val loss 713811.3125\n",
            "Epoch 77: train loss 273.9530011045016 val loss 712668.1875\n",
            "Epoch 78: train loss 273.11892725431 val loss 708330.625\n",
            "Epoch 79: train loss 272.48864184452935 val loss 709231.9375\n",
            "Epoch 80: train loss 271.2964658003587 val loss 712430.6875\n",
            "Epoch 81: train loss 270.6882534320538 val loss 701001.625\n",
            "Epoch 82: train loss 269.12016107999364 val loss 710542.5\n",
            "Epoch 83: train loss 268.0937327575684 val loss 704281.9375\n",
            "Epoch 84: train loss 268.17967094421385 val loss 695607.0625\n",
            "Epoch 85: train loss 266.5801283557598 val loss 699852.8125\n",
            "Epoch 86: train loss 265.52802497276895 val loss 691056.375\n",
            "Epoch 87: train loss 265.0982213709905 val loss 694116.75\n",
            "Epoch 88: train loss 263.3333804438664 val loss 683918.25\n",
            "Epoch 89: train loss 262.97237824073204 val loss 686206.25\n",
            "Epoch 90: train loss 261.4142533815824 val loss 673707.625\n",
            "Epoch 91: train loss 261.03100238506613 val loss 681503.4375\n",
            "Epoch 92: train loss 259.25683716994064 val loss 672593.625\n",
            "Epoch 93: train loss 257.85869607778693 val loss 672717.875\n",
            "Epoch 94: train loss 258.152935732328 val loss 668913.5625\n",
            "Epoch 95: train loss 256.1707276388315 val loss 670603.6875\n",
            "Epoch 96: train loss 255.47444524911734 val loss 671517.8125\n",
            "Epoch 97: train loss 254.78364649259126 val loss 670712.125\n",
            "Epoch 98: train loss 254.20895522484412 val loss 666156.6875\n",
            "Epoch 99: train loss 253.58326303335338 val loss 663202.9375\n",
            "Epoch 100: train loss 252.930464254526 val loss 656898.4375\n",
            "Epoch 101: train loss 251.87978769742526 val loss 650853.625\n",
            "Epoch 102: train loss 251.2614585524339 val loss 657798.125\n",
            "Epoch 103: train loss 251.40947663527268 val loss 660520.375\n",
            "Epoch 104: train loss 249.9134025691106 val loss 650886.5625\n",
            "Epoch 105: train loss 249.59683016850397 val loss 653878.625\n",
            "Epoch 106: train loss 248.16464959364671 val loss 647447.0\n",
            "Epoch 107: train loss 247.05561052175668 val loss 647178.1875\n",
            "Epoch 108: train loss 246.5137626354511 val loss 637438.375\n",
            "Epoch 109: train loss 244.60807552044207 val loss 636155.875\n",
            "Epoch 110: train loss 243.84774136469915 val loss 634609.5625\n",
            "Epoch 111: train loss 242.43625839820274 val loss 633675.125\n",
            "Epoch 112: train loss 241.31559668320875 val loss 628458.6875\n",
            "Epoch 113: train loss 240.46984747079702 val loss 619112.8125\n",
            "Epoch 114: train loss 238.90034186143143 val loss 625736.375\n",
            "Epoch 115: train loss 237.75335395812988 val loss 623297.875\n",
            "Epoch 116: train loss 236.99257070101226 val loss 617403.6875\n",
            "Epoch 117: train loss 236.35819276076097 val loss 620441.5625\n",
            "Epoch 118: train loss 236.72165633568397 val loss 617714.3125\n",
            "Epoch 119: train loss 235.0193455857497 val loss 614641.8125\n",
            "Epoch 120: train loss 234.67260490417482 val loss 607972.8125\n",
            "Epoch 121: train loss 233.53984482985277 val loss 619616.0\n",
            "Epoch 122: train loss 233.42669498150164 val loss 619762.4375\n",
            "Epoch 123: train loss 233.4785324037992 val loss 612687.25\n",
            "Epoch 124: train loss 232.6248353752723 val loss 613053.1875\n",
            "Epoch 125: train loss 232.46560950059157 val loss 607666.3125\n",
            "Epoch 126: train loss 231.3374142221304 val loss 606317.625\n",
            "Epoch 127: train loss 230.93704177856446 val loss 602971.25\n",
            "Epoch 128: train loss 230.89569829500638 val loss 619366.0625\n",
            "Epoch 129: train loss 230.1371272453895 val loss 600906.9375\n",
            "Epoch 130: train loss 229.71005262521598 val loss 598510.375\n",
            "Epoch 131: train loss 229.31646859389085 val loss 601957.3125\n",
            "Epoch 132: train loss 228.7553372837947 val loss 590314.875\n",
            "Epoch 133: train loss 228.5124755859375 val loss 595276.0\n",
            "Epoch 134: train loss 227.97516762953538 val loss 591274.25\n",
            "Epoch 135: train loss 228.33505808316744 val loss 588747.375\n",
            "Epoch 136: train loss 227.10670906653772 val loss 596358.5\n",
            "Epoch 137: train loss 227.38893805870643 val loss 599172.4375\n",
            "Epoch 138: train loss 226.5561902970534 val loss 597381.5\n",
            "Epoch 139: train loss 226.1821704864502 val loss 587294.3125\n",
            "Epoch 140: train loss 226.0687237900954 val loss 603444.75\n",
            "Epoch 141: train loss 226.44972649207483 val loss 596927.9375\n",
            "Epoch 142: train loss 224.90824729332556 val loss 591801.125\n",
            "Epoch 143: train loss 224.80307062002328 val loss 585493.5\n",
            "Epoch 144: train loss 224.49107864379883 val loss 584434.5\n",
            "Epoch 145: train loss 223.88797715994028 val loss 589973.4375\n",
            "Epoch 146: train loss 224.20095878601074 val loss 587047.8125\n",
            "Epoch 147: train loss 223.1749458489051 val loss 580806.1875\n",
            "Epoch 148: train loss 222.8327010521522 val loss 585821.625\n",
            "Epoch 149: train loss 222.82913796058068 val loss 585965.625\n",
            "Epoch 150: train loss 221.95194236168496 val loss 582902.9375\n",
            "Epoch 151: train loss 222.23950725848857 val loss 592404.875\n",
            "Epoch 152: train loss 222.2020644378662 val loss 576031.5625\n",
            "Epoch 153: train loss 220.74792118952826 val loss 582245.6875\n",
            "Epoch 154: train loss 222.28004169757548 val loss 580886.125\n",
            "Epoch 155: train loss 220.5667446077787 val loss 574624.375\n",
            "Epoch 156: train loss 219.7608208817702 val loss 577645.875\n",
            "Epoch 157: train loss 220.5809624657264 val loss 580743.375\n",
            "Epoch 158: train loss 219.92978573725773 val loss 573620.375\n",
            "Epoch 159: train loss 219.14771527216985 val loss 568275.125\n",
            "Epoch 160: train loss 218.34704692547137 val loss 568722.9375\n",
            "Epoch 161: train loss 218.1933208465576 val loss 573623.75\n",
            "Epoch 162: train loss 217.3876906820444 val loss 561948.0\n",
            "Epoch 163: train loss 217.1651004087008 val loss 570338.9375\n",
            "Epoch 164: train loss 220.75451367304876 val loss 572830.125\n",
            "Epoch 165: train loss 219.5589414860652 val loss 564465.6875\n",
            "Epoch 166: train loss 218.05621321458082 val loss 566083.6875\n",
            "Epoch 167: train loss 215.9629318706806 val loss 566620.8125\n",
            "Epoch 168: train loss 215.18374180720403 val loss 554982.3125\n",
            "Epoch 169: train loss 215.03019439697266 val loss 568326.5\n",
            "Epoch 170: train loss 214.24865072983962 val loss 558495.0\n",
            "Epoch 171: train loss 214.00514927203838 val loss 557850.0\n",
            "Epoch 172: train loss 214.08964081397423 val loss 561244.8125\n",
            "Epoch 173: train loss 213.40730143033542 val loss 559505.625\n",
            "Epoch 174: train loss 213.33329956641563 val loss 550901.3125\n",
            "Epoch 175: train loss 211.96623789860652 val loss 558467.125\n",
            "Epoch 176: train loss 213.14060852637658 val loss 551673.125\n",
            "Epoch 177: train loss 211.12926545363206 val loss 552432.6875\n",
            "Epoch 178: train loss 211.56326912513146 val loss 550146.75\n",
            "Epoch 179: train loss 211.1808903855544 val loss 555631.125\n",
            "Epoch 180: train loss 210.05075481708232 val loss 550464.8125\n",
            "Epoch 181: train loss 209.50743283785306 val loss 546842.9375\n",
            "Epoch 182: train loss 209.4935606266902 val loss 552895.25\n",
            "Epoch 183: train loss 209.04924176729642 val loss 546189.3125\n",
            "Epoch 184: train loss 208.68261350191557 val loss 543657.6875\n",
            "Epoch 185: train loss 209.49903315617487 val loss 549505.1875\n",
            "Epoch 186: train loss 207.87347640404334 val loss 541559.4375\n",
            "Epoch 187: train loss 207.74252193744366 val loss 542304.875\n",
            "Epoch 188: train loss 208.28227620051456 val loss 545278.375\n",
            "Epoch 189: train loss 207.3152602151724 val loss 540500.25\n",
            "Epoch 190: train loss 208.23907420818622 val loss 544266.0\n",
            "Epoch 191: train loss 206.86445647019607 val loss 538045.8125\n",
            "Epoch 192: train loss 208.41153913057767 val loss 543136.375\n",
            "Epoch 193: train loss 206.6721070568378 val loss 539342.5625\n",
            "Epoch 194: train loss 206.9031691976694 val loss 546146.9375\n",
            "Epoch 195: train loss 205.90183577904335 val loss 541173.5\n",
            "Epoch 196: train loss 205.9345805828388 val loss 535048.4375\n",
            "Epoch 197: train loss 205.6039918224628 val loss 543972.1875\n",
            "Epoch 198: train loss 204.86893053494967 val loss 526811.75\n",
            "Epoch 199: train loss 205.5695698958177 val loss 547431.5625\n"
          ]
        }
      ],
      "source": [
        "model, history = train_model(model, x_train_y1_scaled , x_train_y1_scaled , \n",
        "                             n_epochs = 200, batch_size=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uXDUxF0m48BW"
      },
      "outputs": [],
      "source": [
        "plt.plot(range(len(history[\"val\"])), history[\"val\"], label = 'validation loss' ) \n",
        "plt.plot(range(len(history[\"train\"])), history[\"train\"], label = 'train loss' ) \n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.title('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fTqMZErnUvZe"
      },
      "outputs": [],
      "source": [
        "# demonstrate reconstruction\n",
        "x_predict = LSTM_ae.predict(x_test_scaled, verbose=0)\n",
        "print('---Predicted---')\n",
        "print(np.round(x_predict,3))\n",
        "print('---Actual---')\n",
        "print(np.round(x_test_scaled, 3))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "LSTM_AE2.ipynb",
      "provenance": [],
      "mount_file_id": "1sp4kqUKbjP3yU0QMkNdlEOFi485LCtES",
      "authorship_tag": "ABX9TyNNQpqXxs3Xbtw0rE9rkqLW",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}