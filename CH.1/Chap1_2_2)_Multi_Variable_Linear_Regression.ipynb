{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/simseoyoung/Deep-Learning/blob/main/CH.1/Chap1_2_2)_Multi_Variable_Linear_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcUYhwq_yc3f"
      },
      "source": [
        "# Linear Regression - Ⅱ\n",
        "-미국 보스턴 지역의 집값을 13개의 Feature를 이용하여 예측하는 모델을 만들어 보자\n",
        "\n",
        "-샘플 개수 : 506개\n",
        "\n",
        "-covariate : 14개 항목"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "t-QZfNPAyc3q"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.utils.data as data_utils\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9DvOzKZyc3z"
      },
      "source": [
        "## [1] Data\n",
        "-Bostion Housing 데이터셋\n",
        "-보스턴 지역의 주변 환경에 대한 수치값과 집값 데이터\n",
        "- Sample수 : 506개\n",
        "- Feature : 14개 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "9SncvuDpyc32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "2af3f8a1-39f0-4e57-bb4c-168dd78f2438"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-b419596dbbe3>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    df_raw =pd.read_csv('C:\\Users\\HOME\\Downloads\\BostonHousing.csv') #csv(comma-separated values)파일 가져오기\u001b[0m\n\u001b[0m                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"
          ]
        }
      ],
      "source": [
        "df_raw =pd.read_csv('C:\\Users\\HOME\\Downloads\\BostonHousing.csv') #csv(comma-separated values)파일 가져오기 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xez2OIUwyc5U",
        "outputId": "ffbd39d2-b133-4b4e-df04-8cd8377d0b6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(506, 14)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>crim</th>\n",
              "      <th>zn</th>\n",
              "      <th>indus</th>\n",
              "      <th>chas</th>\n",
              "      <th>nox</th>\n",
              "      <th>rm</th>\n",
              "      <th>age</th>\n",
              "      <th>dis</th>\n",
              "      <th>rad</th>\n",
              "      <th>tax</th>\n",
              "      <th>ptratio</th>\n",
              "      <th>black</th>\n",
              "      <th>lstat</th>\n",
              "      <th>medv</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00632</td>\n",
              "      <td>18.0</td>\n",
              "      <td>2.31</td>\n",
              "      <td>0</td>\n",
              "      <td>0.538</td>\n",
              "      <td>6.575</td>\n",
              "      <td>65.2</td>\n",
              "      <td>4.0900</td>\n",
              "      <td>1</td>\n",
              "      <td>296</td>\n",
              "      <td>15.3</td>\n",
              "      <td>396.90</td>\n",
              "      <td>4.98</td>\n",
              "      <td>24.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.02731</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>6.421</td>\n",
              "      <td>78.9</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2</td>\n",
              "      <td>242</td>\n",
              "      <td>17.8</td>\n",
              "      <td>396.90</td>\n",
              "      <td>9.14</td>\n",
              "      <td>21.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.02729</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>7.185</td>\n",
              "      <td>61.1</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2</td>\n",
              "      <td>242</td>\n",
              "      <td>17.8</td>\n",
              "      <td>392.83</td>\n",
              "      <td>4.03</td>\n",
              "      <td>34.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.03237</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>6.998</td>\n",
              "      <td>45.8</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3</td>\n",
              "      <td>222</td>\n",
              "      <td>18.7</td>\n",
              "      <td>394.63</td>\n",
              "      <td>2.94</td>\n",
              "      <td>33.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.06905</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>7.147</td>\n",
              "      <td>54.2</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3</td>\n",
              "      <td>222</td>\n",
              "      <td>18.7</td>\n",
              "      <td>396.90</td>\n",
              "      <td>5.33</td>\n",
              "      <td>36.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>501</th>\n",
              "      <td>0.06263</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.93</td>\n",
              "      <td>0</td>\n",
              "      <td>0.573</td>\n",
              "      <td>6.593</td>\n",
              "      <td>69.1</td>\n",
              "      <td>2.4786</td>\n",
              "      <td>1</td>\n",
              "      <td>273</td>\n",
              "      <td>21.0</td>\n",
              "      <td>391.99</td>\n",
              "      <td>9.67</td>\n",
              "      <td>22.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>502</th>\n",
              "      <td>0.04527</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.93</td>\n",
              "      <td>0</td>\n",
              "      <td>0.573</td>\n",
              "      <td>6.120</td>\n",
              "      <td>76.7</td>\n",
              "      <td>2.2875</td>\n",
              "      <td>1</td>\n",
              "      <td>273</td>\n",
              "      <td>21.0</td>\n",
              "      <td>396.90</td>\n",
              "      <td>9.08</td>\n",
              "      <td>20.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>503</th>\n",
              "      <td>0.06076</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.93</td>\n",
              "      <td>0</td>\n",
              "      <td>0.573</td>\n",
              "      <td>6.976</td>\n",
              "      <td>91.0</td>\n",
              "      <td>2.1675</td>\n",
              "      <td>1</td>\n",
              "      <td>273</td>\n",
              "      <td>21.0</td>\n",
              "      <td>396.90</td>\n",
              "      <td>5.64</td>\n",
              "      <td>23.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>504</th>\n",
              "      <td>0.10959</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.93</td>\n",
              "      <td>0</td>\n",
              "      <td>0.573</td>\n",
              "      <td>6.794</td>\n",
              "      <td>89.3</td>\n",
              "      <td>2.3889</td>\n",
              "      <td>1</td>\n",
              "      <td>273</td>\n",
              "      <td>21.0</td>\n",
              "      <td>393.45</td>\n",
              "      <td>6.48</td>\n",
              "      <td>22.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>505</th>\n",
              "      <td>0.04741</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.93</td>\n",
              "      <td>0</td>\n",
              "      <td>0.573</td>\n",
              "      <td>6.030</td>\n",
              "      <td>80.8</td>\n",
              "      <td>2.5050</td>\n",
              "      <td>1</td>\n",
              "      <td>273</td>\n",
              "      <td>21.0</td>\n",
              "      <td>396.90</td>\n",
              "      <td>7.88</td>\n",
              "      <td>11.9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>506 rows × 14 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        crim    zn  indus  chas    nox     rm   age     dis  rad  tax  \\\n",
              "0    0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296   \n",
              "1    0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242   \n",
              "2    0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242   \n",
              "3    0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222   \n",
              "4    0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222   \n",
              "..       ...   ...    ...   ...    ...    ...   ...     ...  ...  ...   \n",
              "501  0.06263   0.0  11.93     0  0.573  6.593  69.1  2.4786    1  273   \n",
              "502  0.04527   0.0  11.93     0  0.573  6.120  76.7  2.2875    1  273   \n",
              "503  0.06076   0.0  11.93     0  0.573  6.976  91.0  2.1675    1  273   \n",
              "504  0.10959   0.0  11.93     0  0.573  6.794  89.3  2.3889    1  273   \n",
              "505  0.04741   0.0  11.93     0  0.573  6.030  80.8  2.5050    1  273   \n",
              "\n",
              "     ptratio   black  lstat  medv  \n",
              "0       15.3  396.90   4.98  24.0  \n",
              "1       17.8  396.90   9.14  21.6  \n",
              "2       17.8  392.83   4.03  34.7  \n",
              "3       18.7  394.63   2.94  33.4  \n",
              "4       18.7  396.90   5.33  36.2  \n",
              "..       ...     ...    ...   ...  \n",
              "501     21.0  391.99   9.67  22.4  \n",
              "502     21.0  396.90   9.08  20.6  \n",
              "503     21.0  396.90   5.64  23.9  \n",
              "504     21.0  393.45   6.48  22.0  \n",
              "505     21.0  396.90   7.88  11.9  \n",
              "\n",
              "[506 rows x 14 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(df_raw.shape) # Dataset의 크기 확인\n",
        "df_raw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d44eqV6iyc5Y",
        "outputId": "6a031f00-df96-4d8b-be3d-f2647a1d2ea2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>crim</th>\n",
              "      <th>zn</th>\n",
              "      <th>indus</th>\n",
              "      <th>chas</th>\n",
              "      <th>nox</th>\n",
              "      <th>rm</th>\n",
              "      <th>age</th>\n",
              "      <th>dis</th>\n",
              "      <th>rad</th>\n",
              "      <th>tax</th>\n",
              "      <th>ptratio</th>\n",
              "      <th>black</th>\n",
              "      <th>lstat</th>\n",
              "      <th>medv</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00632</td>\n",
              "      <td>18.0</td>\n",
              "      <td>2.31</td>\n",
              "      <td>0</td>\n",
              "      <td>0.538</td>\n",
              "      <td>6.575</td>\n",
              "      <td>65.2</td>\n",
              "      <td>4.0900</td>\n",
              "      <td>1</td>\n",
              "      <td>296</td>\n",
              "      <td>15.3</td>\n",
              "      <td>396.90</td>\n",
              "      <td>4.98</td>\n",
              "      <td>24.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.02731</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>6.421</td>\n",
              "      <td>78.9</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2</td>\n",
              "      <td>242</td>\n",
              "      <td>17.8</td>\n",
              "      <td>396.90</td>\n",
              "      <td>9.14</td>\n",
              "      <td>21.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.02729</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>7.185</td>\n",
              "      <td>61.1</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2</td>\n",
              "      <td>242</td>\n",
              "      <td>17.8</td>\n",
              "      <td>392.83</td>\n",
              "      <td>4.03</td>\n",
              "      <td>34.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.03237</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>6.998</td>\n",
              "      <td>45.8</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3</td>\n",
              "      <td>222</td>\n",
              "      <td>18.7</td>\n",
              "      <td>394.63</td>\n",
              "      <td>2.94</td>\n",
              "      <td>33.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.06905</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>7.147</td>\n",
              "      <td>54.2</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3</td>\n",
              "      <td>222</td>\n",
              "      <td>18.7</td>\n",
              "      <td>396.90</td>\n",
              "      <td>5.33</td>\n",
              "      <td>36.2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      crim    zn  indus  chas    nox     rm   age     dis  rad  tax  ptratio  \\\n",
              "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296     15.3   \n",
              "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242     17.8   \n",
              "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242     17.8   \n",
              "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222     18.7   \n",
              "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222     18.7   \n",
              "\n",
              "    black  lstat  medv  \n",
              "0  396.90   4.98  24.0  \n",
              "1  396.90   9.14  21.6  \n",
              "2  392.83   4.03  34.7  \n",
              "3  394.63   2.94  33.4  \n",
              "4  396.90   5.33  36.2  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_raw.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "8jMpbM4Tyc5Z",
        "outputId": "79265a58-1286-428e-bc15-ffe81463ffef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-cd38a88395f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# X값 coulumn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_raw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'medv'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# y값 column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_raw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'medv'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df_raw' is not defined"
          ]
        }
      ],
      "source": [
        "# X값 coulumn\n",
        "x = df_raw.drop(['medv'], axis=1)\n",
        "\n",
        "# y값 column\n",
        "y = df_raw['medv']\n",
        "\n",
        "print(x.shape)\n",
        "print(y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OAq3rFH9yc5i",
        "outputId": "6526e32a-82d8-4651-beda-6a9ae714abb8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x_train의 크기:  (354, 13)\n",
            "y_train의 크기:  (354,) \n",
            "\n",
            "x_test의 크기:  (152, 13)\n",
            "y_test의 크기:  (152,)\n",
            "<class 'pandas.core.series.Series'>\n"
          ]
        }
      ],
      "source": [
        "#학습데이터와 테스트데이터를 일정비율로 나누기\n",
        "#training/test=validation으로 나눔 -> overfitting되는지 확인하기 위함\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size= 0.3, random_state=1234)\n",
        "\n",
        "#학습 데이터\n",
        "print(\"x_train의 크기: \",x_train.shape)\n",
        "print(\"y_train의 크기: \",y_train.shape,'\\n')\n",
        "\n",
        "#테스트 데이터 \n",
        "print(\"x_test의 크기: \",x_test.shape)\n",
        "print(\"y_test의 크기: \",y_test.shape)\n",
        "print(type(y_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Tkk72Hkyc5l"
      },
      "outputs": [],
      "source": [
        "#학습 데이터 Scaling\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(x_train)\n",
        "x_train_scale =  scaler.transform(x_train)  # x_train_scale은 numpy ndarray \n",
        "\n",
        "\n",
        "#테스트 데이터 Scaling\n",
        "x_test_scale = scaler.transform(x_test)    # x_test_scale은 numpy ndarray \n",
        "\n",
        "\n",
        "# Array-->Tensor\n",
        "x_train_tensor = torch.FloatTensor(x_train_scale)\n",
        "y_train_tensor = torch.FloatTensor(y_train.values) #판다스 Series이므로 values를 사용해서 numpy ndarray로 가져오기\n",
        "\n",
        "x_test_tensor = torch.FloatTensor(x_test_scale)\n",
        "y_test_tensor = torch.FloatTensor(y_test.values)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QmT5UyT9yc5n",
        "outputId": "1885d431-c3b3-4341-e845-aa83d0a2864a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "torch.Size([100, 13])\n",
            "torch.Size([100])\n"
          ]
        }
      ],
      "source": [
        "#학습 데이터 배치화 시키기 \n",
        "#전체 데이터셋이 너무 클 때는 1 epoch로 사용하기에는 하드웨어에 부담이 되므로 batch로 쪼갬\n",
        "#mini batch의 개수 = iteration = batch_size\n",
        "train_data =  data_utils.TensorDataset(x_train_tensor, y_train_tensor)\n",
        "\n",
        "dataloader =  data_utils.DataLoader(train_data, batch_size=100, shuffle= True, drop_last= True )\n",
        "#shuffle을 통해 random하게 나눔\n",
        "#drop_last를 통해 총 354개를 100개씩 batch로 나누고 남은 54개를 drop함\n",
        "\n",
        "#배치화된 데이터 확인\n",
        "for batch_idx, datas in enumerate(dataloader):\n",
        "    \n",
        "    print(batch_idx)\n",
        "    print(datas[0].shape)  # x_train \n",
        "    print(datas[1].shape) # y_train\n",
        "    break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4EA2HC7yc5w"
      },
      "source": [
        "## [2] Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SJtdadWTyc5y"
      },
      "outputs": [],
      "source": [
        "#Parameter 정의\n",
        "input_size = 13\n",
        "output_size = 1\n",
        "learning_rate = 0.1\n",
        "n_epochs = 200"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D4D9O553yc6s"
      },
      "outputs": [],
      "source": [
        "#model 생성\n",
        "model = torch.nn.Linear(input_size, output_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UX2KDnP6yc60"
      },
      "outputs": [],
      "source": [
        "#손실함수 생성\n",
        "criterion = torch.nn.MSELoss()\n",
        "#Optimizer 생성\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr= learning_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFhoHdCYyc61"
      },
      "source": [
        "## [3]Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w0ZAo-AZyc62",
        "outputId": "17109331-1a7c-463f-bc1c-460155a01f37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch:0, Loss_train:235.77, Loss_test:167.39\n",
            "epoch:1, Loss_train:91.72, Loss_test:64.98\n",
            "epoch:2, Loss_train:41.23, Loss_test:34.55\n",
            "epoch:3, Loss_train:17.21, Loss_test:24.41\n",
            "epoch:4, Loss_train:22.68, Loss_test:21.86\n",
            "epoch:5, Loss_train:31.58, Loss_test:22.58\n",
            "epoch:6, Loss_train:37.07, Loss_test:21.60\n",
            "epoch:7, Loss_train:32.22, Loss_test:21.69\n",
            "epoch:8, Loss_train:27.99, Loss_test:23.04\n",
            "epoch:9, Loss_train:30.01, Loss_test:22.50\n",
            "epoch:10, Loss_train:28.46, Loss_test:23.36\n",
            "epoch:11, Loss_train:28.09, Loss_test:23.16\n",
            "epoch:12, Loss_train:19.05, Loss_test:22.15\n",
            "epoch:13, Loss_train:19.36, Loss_test:23.23\n",
            "epoch:14, Loss_train:16.40, Loss_test:22.46\n",
            "epoch:15, Loss_train:24.18, Loss_test:23.66\n",
            "epoch:16, Loss_train:30.69, Loss_test:23.22\n",
            "epoch:17, Loss_train:20.46, Loss_test:23.01\n",
            "epoch:18, Loss_train:23.27, Loss_test:23.32\n",
            "epoch:19, Loss_train:17.62, Loss_test:23.53\n",
            "epoch:20, Loss_train:28.72, Loss_test:23.86\n",
            "epoch:21, Loss_train:19.03, Loss_test:23.61\n",
            "epoch:22, Loss_train:28.27, Loss_test:24.46\n",
            "epoch:23, Loss_train:22.34, Loss_test:24.06\n",
            "epoch:24, Loss_train:28.33, Loss_test:23.63\n",
            "epoch:25, Loss_train:13.17, Loss_test:24.12\n",
            "epoch:26, Loss_train:41.61, Loss_test:25.71\n",
            "epoch:27, Loss_train:21.53, Loss_test:23.86\n",
            "epoch:28, Loss_train:13.25, Loss_test:24.11\n",
            "epoch:29, Loss_train:18.73, Loss_test:23.38\n",
            "epoch:30, Loss_train:25.06, Loss_test:24.00\n",
            "epoch:31, Loss_train:22.76, Loss_test:23.89\n",
            "epoch:32, Loss_train:23.93, Loss_test:24.27\n",
            "epoch:33, Loss_train:14.21, Loss_test:23.44\n",
            "epoch:34, Loss_train:18.13, Loss_test:23.30\n",
            "epoch:35, Loss_train:15.65, Loss_test:23.54\n",
            "epoch:36, Loss_train:27.08, Loss_test:24.19\n",
            "epoch:37, Loss_train:19.88, Loss_test:23.91\n",
            "epoch:38, Loss_train:22.91, Loss_test:24.55\n",
            "epoch:39, Loss_train:21.78, Loss_test:24.12\n",
            "epoch:40, Loss_train:14.97, Loss_test:23.19\n",
            "epoch:41, Loss_train:22.65, Loss_test:23.19\n",
            "epoch:42, Loss_train:29.37, Loss_test:22.56\n",
            "epoch:43, Loss_train:18.13, Loss_test:23.29\n",
            "epoch:44, Loss_train:24.60, Loss_test:23.63\n",
            "epoch:45, Loss_train:16.45, Loss_test:23.50\n",
            "epoch:46, Loss_train:26.23, Loss_test:25.33\n",
            "epoch:47, Loss_train:17.98, Loss_test:23.64\n",
            "epoch:48, Loss_train:23.95, Loss_test:23.15\n",
            "epoch:49, Loss_train:20.63, Loss_test:23.40\n",
            "epoch:50, Loss_train:21.13, Loss_test:23.35\n",
            "epoch:51, Loss_train:32.91, Loss_test:25.92\n",
            "epoch:52, Loss_train:25.06, Loss_test:23.38\n",
            "epoch:53, Loss_train:24.14, Loss_test:23.63\n",
            "epoch:54, Loss_train:20.95, Loss_test:23.60\n",
            "epoch:55, Loss_train:19.75, Loss_test:23.37\n",
            "epoch:56, Loss_train:24.76, Loss_test:25.41\n",
            "epoch:57, Loss_train:19.93, Loss_test:25.93\n",
            "epoch:58, Loss_train:27.80, Loss_test:23.68\n",
            "epoch:59, Loss_train:18.11, Loss_test:23.81\n",
            "epoch:60, Loss_train:26.87, Loss_test:23.97\n",
            "epoch:61, Loss_train:23.76, Loss_test:25.15\n",
            "epoch:62, Loss_train:17.93, Loss_test:23.93\n",
            "epoch:63, Loss_train:23.94, Loss_test:23.82\n",
            "epoch:64, Loss_train:25.02, Loss_test:24.05\n",
            "epoch:65, Loss_train:14.02, Loss_test:23.61\n",
            "epoch:66, Loss_train:22.07, Loss_test:24.04\n",
            "epoch:67, Loss_train:20.70, Loss_test:24.21\n",
            "epoch:68, Loss_train:24.93, Loss_test:24.35\n",
            "epoch:69, Loss_train:18.28, Loss_test:23.90\n",
            "epoch:70, Loss_train:31.79, Loss_test:25.82\n",
            "epoch:71, Loss_train:25.41, Loss_test:24.02\n",
            "epoch:72, Loss_train:20.56, Loss_test:23.63\n",
            "epoch:73, Loss_train:19.14, Loss_test:23.28\n",
            "epoch:74, Loss_train:18.15, Loss_test:23.87\n",
            "epoch:75, Loss_train:26.49, Loss_test:23.46\n",
            "epoch:76, Loss_train:27.53, Loss_test:25.24\n",
            "epoch:77, Loss_train:12.84, Loss_test:24.25\n",
            "epoch:78, Loss_train:17.68, Loss_test:24.99\n",
            "epoch:79, Loss_train:27.97, Loss_test:25.98\n",
            "epoch:80, Loss_train:23.97, Loss_test:24.01\n",
            "epoch:81, Loss_train:15.53, Loss_test:24.47\n",
            "epoch:82, Loss_train:22.26, Loss_test:25.61\n",
            "epoch:83, Loss_train:18.88, Loss_test:24.02\n",
            "epoch:84, Loss_train:32.91, Loss_test:25.64\n",
            "epoch:85, Loss_train:20.72, Loss_test:24.22\n",
            "epoch:86, Loss_train:25.67, Loss_test:23.95\n",
            "epoch:87, Loss_train:26.46, Loss_test:24.32\n",
            "epoch:88, Loss_train:33.21, Loss_test:26.47\n",
            "epoch:89, Loss_train:23.50, Loss_test:25.07\n",
            "epoch:90, Loss_train:18.95, Loss_test:24.44\n",
            "epoch:91, Loss_train:20.42, Loss_test:24.94\n",
            "epoch:92, Loss_train:19.50, Loss_test:24.32\n",
            "epoch:93, Loss_train:17.80, Loss_test:24.61\n",
            "epoch:94, Loss_train:25.50, Loss_test:24.78\n",
            "epoch:95, Loss_train:22.81, Loss_test:24.83\n",
            "epoch:96, Loss_train:29.28, Loss_test:26.84\n",
            "epoch:97, Loss_train:12.27, Loss_test:23.74\n",
            "epoch:98, Loss_train:24.64, Loss_test:26.47\n",
            "epoch:99, Loss_train:21.78, Loss_test:24.70\n",
            "epoch:100, Loss_train:21.45, Loss_test:23.96\n",
            "epoch:101, Loss_train:30.89, Loss_test:25.51\n",
            "epoch:102, Loss_train:34.10, Loss_test:25.91\n",
            "epoch:103, Loss_train:26.41, Loss_test:24.10\n",
            "epoch:104, Loss_train:28.46, Loss_test:23.44\n",
            "epoch:105, Loss_train:22.56, Loss_test:23.49\n",
            "epoch:106, Loss_train:12.51, Loss_test:24.41\n",
            "epoch:107, Loss_train:18.16, Loss_test:24.16\n",
            "epoch:108, Loss_train:21.72, Loss_test:23.59\n",
            "epoch:109, Loss_train:25.09, Loss_test:23.78\n",
            "epoch:110, Loss_train:33.63, Loss_test:27.22\n",
            "epoch:111, Loss_train:24.26, Loss_test:25.15\n",
            "epoch:112, Loss_train:30.72, Loss_test:25.88\n",
            "epoch:113, Loss_train:33.69, Loss_test:23.72\n",
            "epoch:114, Loss_train:26.75, Loss_test:23.55\n",
            "epoch:115, Loss_train:27.23, Loss_test:23.05\n",
            "epoch:116, Loss_train:13.34, Loss_test:23.17\n",
            "epoch:117, Loss_train:38.22, Loss_test:26.54\n",
            "epoch:118, Loss_train:24.36, Loss_test:24.55\n",
            "epoch:119, Loss_train:20.00, Loss_test:23.47\n",
            "epoch:120, Loss_train:27.23, Loss_test:25.55\n",
            "epoch:121, Loss_train:31.61, Loss_test:23.90\n",
            "epoch:122, Loss_train:26.80, Loss_test:24.99\n",
            "epoch:123, Loss_train:34.02, Loss_test:29.23\n",
            "epoch:124, Loss_train:28.87, Loss_test:23.55\n",
            "epoch:125, Loss_train:14.24, Loss_test:23.61\n",
            "epoch:126, Loss_train:31.99, Loss_test:24.54\n",
            "epoch:127, Loss_train:25.05, Loss_test:24.67\n",
            "epoch:128, Loss_train:22.14, Loss_test:24.08\n",
            "epoch:129, Loss_train:15.91, Loss_test:25.38\n",
            "epoch:130, Loss_train:18.65, Loss_test:24.12\n",
            "epoch:131, Loss_train:24.37, Loss_test:24.65\n",
            "epoch:132, Loss_train:27.21, Loss_test:26.42\n",
            "epoch:133, Loss_train:31.42, Loss_test:25.10\n",
            "epoch:134, Loss_train:17.45, Loss_test:24.51\n",
            "epoch:135, Loss_train:28.37, Loss_test:24.47\n",
            "epoch:136, Loss_train:23.59, Loss_test:25.02\n",
            "epoch:137, Loss_train:20.36, Loss_test:24.50\n",
            "epoch:138, Loss_train:19.99, Loss_test:24.24\n",
            "epoch:139, Loss_train:21.52, Loss_test:23.54\n",
            "epoch:140, Loss_train:22.76, Loss_test:23.59\n",
            "epoch:141, Loss_train:19.26, Loss_test:23.89\n",
            "epoch:142, Loss_train:35.72, Loss_test:27.66\n",
            "epoch:143, Loss_train:28.24, Loss_test:23.79\n",
            "epoch:144, Loss_train:17.27, Loss_test:24.06\n",
            "epoch:145, Loss_train:15.29, Loss_test:23.38\n",
            "epoch:146, Loss_train:27.66, Loss_test:23.99\n",
            "epoch:147, Loss_train:19.37, Loss_test:23.71\n",
            "epoch:148, Loss_train:25.46, Loss_test:24.11\n",
            "epoch:149, Loss_train:17.36, Loss_test:23.35\n",
            "epoch:150, Loss_train:22.53, Loss_test:24.07\n",
            "epoch:151, Loss_train:33.58, Loss_test:25.52\n",
            "epoch:152, Loss_train:15.51, Loss_test:23.54\n",
            "epoch:153, Loss_train:15.99, Loss_test:23.53\n",
            "epoch:154, Loss_train:25.93, Loss_test:23.80\n",
            "epoch:155, Loss_train:25.31, Loss_test:23.45\n",
            "epoch:156, Loss_train:17.62, Loss_test:23.70\n",
            "epoch:157, Loss_train:28.84, Loss_test:24.82\n",
            "epoch:158, Loss_train:22.26, Loss_test:23.76\n",
            "epoch:159, Loss_train:16.05, Loss_test:24.00\n",
            "epoch:160, Loss_train:25.23, Loss_test:24.55\n",
            "epoch:161, Loss_train:35.27, Loss_test:26.20\n",
            "epoch:162, Loss_train:17.54, Loss_test:24.10\n",
            "epoch:163, Loss_train:17.27, Loss_test:23.52\n",
            "epoch:164, Loss_train:15.58, Loss_test:24.61\n",
            "epoch:165, Loss_train:15.30, Loss_test:23.40\n",
            "epoch:166, Loss_train:24.04, Loss_test:23.23\n",
            "epoch:167, Loss_train:18.66, Loss_test:27.27\n",
            "epoch:168, Loss_train:24.08, Loss_test:25.01\n",
            "epoch:169, Loss_train:16.11, Loss_test:24.06\n",
            "epoch:170, Loss_train:22.55, Loss_test:24.22\n",
            "epoch:171, Loss_train:19.35, Loss_test:26.98\n",
            "epoch:172, Loss_train:25.99, Loss_test:24.71\n",
            "epoch:173, Loss_train:24.36, Loss_test:23.96\n",
            "epoch:174, Loss_train:13.33, Loss_test:24.80\n",
            "epoch:175, Loss_train:16.66, Loss_test:24.44\n",
            "epoch:176, Loss_train:30.18, Loss_test:24.73\n",
            "epoch:177, Loss_train:22.05, Loss_test:24.12\n",
            "epoch:178, Loss_train:32.45, Loss_test:25.52\n",
            "epoch:179, Loss_train:15.86, Loss_test:23.69\n",
            "epoch:180, Loss_train:30.24, Loss_test:24.72\n",
            "epoch:181, Loss_train:30.41, Loss_test:29.21\n",
            "epoch:182, Loss_train:23.02, Loss_test:24.18\n",
            "epoch:183, Loss_train:27.77, Loss_test:25.13\n",
            "epoch:184, Loss_train:25.69, Loss_test:24.23\n",
            "epoch:185, Loss_train:15.25, Loss_test:24.21\n",
            "epoch:186, Loss_train:26.38, Loss_test:24.55\n",
            "epoch:187, Loss_train:20.71, Loss_test:27.16\n",
            "epoch:188, Loss_train:29.27, Loss_test:28.51\n",
            "epoch:189, Loss_train:24.57, Loss_test:24.68\n",
            "epoch:190, Loss_train:29.22, Loss_test:26.48\n",
            "epoch:191, Loss_train:14.62, Loss_test:25.05\n",
            "epoch:192, Loss_train:21.93, Loss_test:25.02\n",
            "epoch:193, Loss_train:25.24, Loss_test:24.65\n",
            "epoch:194, Loss_train:20.72, Loss_test:24.11\n",
            "epoch:195, Loss_train:23.64, Loss_test:24.94\n",
            "epoch:196, Loss_train:21.60, Loss_test:23.75\n",
            "epoch:197, Loss_train:17.16, Loss_test:25.09\n",
            "epoch:198, Loss_train:25.73, Loss_test:25.17\n",
            "epoch:199, Loss_train:17.25, Loss_test:24.04\n",
            "epoch:200, Loss_train:21.29, Loss_test:24.23\n"
          ]
        }
      ],
      "source": [
        "## Running the model\n",
        "train_loss = []\n",
        "test_loss = []\n",
        "\n",
        "for epoch in range(n_epochs+1):\n",
        "    \n",
        "    for idx, (x_batch, y_batch) in enumerate(dataloader):\n",
        "        #Batch 학습\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        y_pred = model(x_batch)\n",
        "        y_pred = y_pred.reshape(-1)\n",
        "        \n",
        "        loss_train = criterion(y_pred, y_batch)\n",
        "        \n",
        "        loss_train.backward() #gradient 값 구함\n",
        "        optimizer.step()\n",
        "\n",
        "        \n",
        "        #Validation\n",
        "        #overfitting되는지 확인\n",
        "        model.eval()\n",
        "        y_test_pred = model(x_test_tensor)\n",
        "        \n",
        "        y_test_pred = y_test_pred.reshape(-1)\n",
        "        \n",
        "        loss_test = criterion(y_test_pred, y_test_tensor)\n",
        "        \n",
        "        \n",
        "        \n",
        "   \n",
        "    train_loss.append(loss_train.item()) #epoch 수 만큼 append 됨\n",
        "    test_loss.append(loss_test.item())\n",
        "    print(\"epoch:{}, Loss_train:{:.2f}, Loss_test:{:.2f}\".format( epoch, train_loss[-1], test_loss[-1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5XSaxkL4yc64",
        "outputId": "1ff689c8-c4a3-46f5-9e2b-10b56681308b"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Loss 값 plot\n",
        "# overfitting이 됐다면 train loss가 test loss와 달리 위에 있음\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(train_loss, label='train')\n",
        "plt.plot(test_loss, label='test')\n",
        "plt.title('Model loss')\n",
        "plt.legend(loc= 'upper right')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYL2Sf1vyc65"
      },
      "source": [
        "### <Scaling>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFHo0L71yc66"
      },
      "source": [
        "### Tip) Scaling\n",
        "\n",
        "- 정규분포를 사용하는 방식\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1aqswHwByc7J"
      },
      "source": [
        "$$ x_in = \\frac{x_io - \\mu_i}{\\sigma_i} $$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "YLEGQg89yc7K",
        "outputId": "60d032d1-8037-4252-dde8-a7741ea41b10",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4, 2)\n",
            "[0.5 4. ]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.25"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "data = [[0, 0], [0, 0], [1, 8], [1, 8]]\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(data)\n",
        "data_arr= np.array(data)\n",
        "\n",
        "print(data_arr.shape)\n",
        "print(np.mean(data_arr, axis= 0))\n",
        "data_arr.mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j-UNzyEJyc7L",
        "outputId": "f3ea115e-08dd-4025-ef0a-35fbb78063e0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[-1., -1.],\n",
              "       [-1., -1.],\n",
              "       [ 1.,  1.],\n",
              "       [ 1.,  1.]])"
            ]
          },
          "execution_count": 130,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_arr_scaler=scaler.transform(data_arr)\n",
        "data_arr_scaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JEQiY0pByc7P",
        "outputId": "643e2cf1-7afb-461b-df12-8b7789f16c30"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 3. , -0.5]])"
            ]
          },
          "execution_count": 131,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "scaler.transform([[2, 2]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Zwkx6YRyc7Q",
        "outputId": "df9f12ed-0c56-414c-c3be-c36a0406fa33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[-1. -1.]\n",
            " [-1. -1.]\n",
            " [ 1.  1.]\n",
            " [ 1.  1.]]\n"
          ]
        }
      ],
      "source": [
        "print(data_arr_scaler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fpayAY-Syc8V",
        "outputId": "268ae80b-ed09-4fb0-a96b-75f869703754"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0., 0.])"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.mean(data_arr_scaler, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x8NU_FA2yc8Z",
        "outputId": "16f6c028-690c-43ee-8cce-28699a17f714"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_arr_scaler.mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rN2Mx-3Ryc8b",
        "outputId": "8684ff27-e279-4fde-8411-79bfa0b3b570"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_arr_scaler.std()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MPCIFnNNyc8c"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Chap1-2-2)_Multi_Variable_Linear_Regression.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}