{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled4.ipynb",
      "provenance": [],
      "mount_file_id": "1AJXESw7nNTzd632w8iHYZARzSxHD5L9D",
      "authorship_tag": "ABX9TyO/HlApsDIkVCnyBA0+hvsz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/simseoyoung/Deep-Learning/blob/main/CH.2/MLP-Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MLP(Multi Layer Perceptron) - Regression\n",
        "\n",
        "- CH.1에서 사용했던 Marketing.csv 파일 사용"
      ],
      "metadata": {
        "id": "H9EhydFZCcKq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rHhM0FpUCbag"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.utils.data as data_utils\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[1] Data Processing"
      ],
      "metadata": {
        "id": "5U5vU3-vDiRA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 파일 불러오기\n",
        "train_data_url = \"/content/drive/MyDrive/DL 실습/marketing.csv\"\n",
        "df = pd.read_csv(train_data_url)\n",
        "print (df.shape) # 파일 형식 확인\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "id": "NvfxEkKDC2ju",
        "outputId": "1fe469ee-33c3-4991-acd8-2a1226900039"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(200, 4)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     youtube  facebook  newspaper  sales\n",
              "0     276.12     45.36      83.04  26.52\n",
              "1      53.40     47.16      54.12  12.48\n",
              "2      20.64     55.08      83.16  11.16\n",
              "3     181.80     49.56      70.20  22.20\n",
              "4     216.96     12.96      70.08  15.48\n",
              "..       ...       ...        ...    ...\n",
              "195    45.84      4.44      16.56   9.12\n",
              "196   113.04      5.88       9.72  11.64\n",
              "197   212.40     11.16       7.68  15.36\n",
              "198   340.32     50.40      79.44  30.60\n",
              "199   278.52     10.32      10.44  16.08\n",
              "\n",
              "[200 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c2e6af77-a0f1-4a8e-86ad-74f5783a3cca\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>youtube</th>\n",
              "      <th>facebook</th>\n",
              "      <th>newspaper</th>\n",
              "      <th>sales</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>276.12</td>\n",
              "      <td>45.36</td>\n",
              "      <td>83.04</td>\n",
              "      <td>26.52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>53.40</td>\n",
              "      <td>47.16</td>\n",
              "      <td>54.12</td>\n",
              "      <td>12.48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>20.64</td>\n",
              "      <td>55.08</td>\n",
              "      <td>83.16</td>\n",
              "      <td>11.16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>181.80</td>\n",
              "      <td>49.56</td>\n",
              "      <td>70.20</td>\n",
              "      <td>22.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>216.96</td>\n",
              "      <td>12.96</td>\n",
              "      <td>70.08</td>\n",
              "      <td>15.48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195</th>\n",
              "      <td>45.84</td>\n",
              "      <td>4.44</td>\n",
              "      <td>16.56</td>\n",
              "      <td>9.12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>196</th>\n",
              "      <td>113.04</td>\n",
              "      <td>5.88</td>\n",
              "      <td>9.72</td>\n",
              "      <td>11.64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>197</th>\n",
              "      <td>212.40</td>\n",
              "      <td>11.16</td>\n",
              "      <td>7.68</td>\n",
              "      <td>15.36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>198</th>\n",
              "      <td>340.32</td>\n",
              "      <td>50.40</td>\n",
              "      <td>79.44</td>\n",
              "      <td>30.60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199</th>\n",
              "      <td>278.52</td>\n",
              "      <td>10.32</td>\n",
              "      <td>10.44</td>\n",
              "      <td>16.08</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>200 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c2e6af77-a0f1-4a8e-86ad-74f5783a3cca')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c2e6af77-a0f1-4a8e-86ad-74f5783a3cca button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c2e6af77-a0f1-4a8e-86ad-74f5783a3cca');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# X값 coulumn\n",
        "x = df.drop([\"sales\"], axis=1) \n",
        "\n",
        "# y값 column\n",
        "y = df[\"sales\"]\n",
        "\n",
        "print(x.shape)\n",
        "print(y.shape)\n",
        "print(type(y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_-83q3KDRIy",
        "outputId": "260f92d7-1603-43fd-dcc6-a1b635277152"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(200, 3)\n",
            "(200,)\n",
            "<class 'pandas.core.series.Series'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#학습데이터와 테스트데이터를 일정비율로 나누기\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size= 0.3, random_state=1234)\n",
        "\n",
        "#학습 데이터\n",
        "print(\"x_train의 크기: \",x_train.shape)\n",
        "print(\"y_train의 크기: \",y_train.shape,'\\n')\n",
        "\n",
        "#테스트 데이터 \n",
        "print(\"x_test의 크기: \",x_test.shape)\n",
        "print(\"y_test의 크기: \",y_test.shape)\n",
        "print(type(y_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3CPlfSdnDbJp",
        "outputId": "4b051063-a405-4183-f7db-251af59d75c4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train의 크기:  (140, 3)\n",
            "y_train의 크기:  (140,) \n",
            "\n",
            "x_test의 크기:  (60, 3)\n",
            "y_test의 크기:  (60,)\n",
            "<class 'pandas.core.series.Series'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#학습 데이터 Scaling\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(x_train)\n",
        "x_train_scale = scaler.transform(x_train) # x_train_scale은 numpy ndarray \n",
        "\n",
        "\n",
        "#테스트 데이터 Scaling\n",
        "x_test_scale = scaler.transform(x_test) # x_test_scale은 numpy ndarray \n",
        "\n",
        "\n",
        "# Array-->Tensor\n",
        "x_train_tensor = torch.FloatTensor(x_train_scale)\n",
        "y_train_tensor = torch.FloatTensor(y_train.values) #y_train은 판다스 Series이므로 values를 사용해서 numpy ndarray로 가져오기\n",
        "\n",
        "x_test_tensor = torch.FloatTensor(x_test_scale)\n",
        "y_test_tensor = torch.FloatTensor(y_test.values)"
      ],
      "metadata": {
        "id": "6BDI4UN4DlfT"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#학습 데이터 배치화 시키기 \n",
        "train_data = data_utils.TensorDataset(x_train_tensor, y_train_tensor)\n",
        "\n",
        "dataloader = data_utils.DataLoader(train_data, batch_size=32, shuffle=True , drop_last=True)\n",
        "\n",
        "\n",
        "#배치화된 데이터 확인\n",
        "for batch_idx, datas in enumerate(dataloader):\n",
        "    print(batch_idx)\n",
        "    print(datas[0].shape)  # x_train \n",
        "    print(datas[1].shape) # y_train\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iPdyKyshDovE",
        "outputId": "507798c4-2d7d-42e3-c746-a85b9f1db470"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "torch.Size([32, 3])\n",
            "torch.Size([32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[2] Model"
      ],
      "metadata": {
        "id": "8aAoAHsxDvUz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP_model(torch.nn.Module):\n",
        "        def __init__(self, input_size, hidden_size ,output_size):\n",
        "            super(MLP_model, self).__init__()\n",
        "            self.input_size = input_size\n",
        "            self.hidden_size = hidden_size\n",
        "            self.output_size = output_size\n",
        "            self.hidden2 = 16\n",
        "            \n",
        "            #MLP이기 때문에 여러 개의 함수 필요 이때 변수 값 주의\n",
        "            self.fc1 = torch.nn.Linear(self.input_size, self.hidden_size)\n",
        "            self.fc2 = torch.nn.Linear(self.hidden_size, self.hidden2)\n",
        "            self.fc3 = torch.nn.Linear(self.hidden2, self.output_size)\n",
        "            self.relu = torch.nn.ReLU()\n",
        "            self.sig = torch.nn.Sigmoid()\n",
        "            \n",
        "        def forward(self, x):\n",
        "            fc1 = self.fc1(x)\n",
        "            ac1 = self.relu(fc1)\n",
        "            fc2 = self.fc2(ac1)\n",
        "            ac2 = self.relu(fc2)\n",
        "            fc3 = self.fc3(ac2)\n",
        "\n",
        "\n",
        "            return fc3"
      ],
      "metadata": {
        "id": "P2ITFTGDDwfI"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Parameter 정의\n",
        "input_dim = 3\n",
        "output_dim = 1\n",
        "hidden_dim = 32 #대체로 2의 배수로 사용\n",
        "learning_rate = 0.01\n",
        "n_epochs = 700\n",
        "\n",
        "#model 생성\n",
        "model = MLP_model(input_size = input_dim, hidden_size = hidden_dim, output_size = output_dim)"
      ],
      "metadata": {
        "id": "0ASvo5HbD2oX"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#손실함수 생성\n",
        "criterion = torch.nn.MSELoss()\n",
        "#Optimizer 생성\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "epZfex4nD86v"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[3] Training"
      ],
      "metadata": {
        "id": "1JMQBtGdEAil"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss = []\n",
        "test_loss = []\n",
        "\n",
        "for epoch in range(n_epochs+1):\n",
        "    \n",
        "    #Batch 학습\n",
        "    for idx, (x_batch, y_batch) in enumerate(dataloader):\n",
        "        optimizer.zero_grad() #gradient 값 초기화\n",
        "        y_pred = model(x_batch)\n",
        "        y_pred = y_pred.reshape(-1)\n",
        "        loss_train = criterion(y_pred, y_batch)\n",
        "        loss_train.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        #Validation\n",
        "        y_test_pred = model(x_test_tensor)\n",
        "        y_test_pred = y_test_pred.reshape(-1) #차원을 맞춰야 loss값을 정확히 알 수 있음\n",
        "        loss_test = criterion(y_test_pred, y_test_tensor)\n",
        "\n",
        "    train_loss.append(loss_train.item())\n",
        "    test_loss.append(loss_test.item())\n",
        "    print(\"epoch:{}, Loss_train:{:.2f}, Loss_test:{:.2f}\".format( epoch, train_loss[-1], test_loss[-1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJxsY9mEEAR4",
        "outputId": "dd4e1cf8-ed5e-4092-cab1-79db7af26989"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:0, Loss_train:234.83, Loss_test:126.71\n",
            "epoch:1, Loss_train:17.79, Loss_test:21.95\n",
            "epoch:2, Loss_train:40.39, Loss_test:57.63\n",
            "epoch:3, Loss_train:10.58, Loss_test:4.73\n",
            "epoch:4, Loss_train:7.50, Loss_test:6.38\n",
            "epoch:5, Loss_train:21.52, Loss_test:12.97\n",
            "epoch:6, Loss_train:27.88, Loss_test:15.52\n",
            "epoch:7, Loss_train:37.22, Loss_test:18.34\n",
            "epoch:8, Loss_train:3.31, Loss_test:3.82\n",
            "epoch:9, Loss_train:5.50, Loss_test:7.51\n",
            "epoch:10, Loss_train:33.40, Loss_test:11.61\n",
            "epoch:11, Loss_train:16.99, Loss_test:11.85\n",
            "epoch:12, Loss_train:10.66, Loss_test:12.73\n",
            "epoch:13, Loss_train:8.75, Loss_test:10.63\n",
            "epoch:14, Loss_train:6.10, Loss_test:6.73\n",
            "epoch:15, Loss_train:3.69, Loss_test:6.35\n",
            "epoch:16, Loss_train:5.59, Loss_test:8.34\n",
            "epoch:17, Loss_train:15.79, Loss_test:11.61\n",
            "epoch:18, Loss_train:7.30, Loss_test:7.19\n",
            "epoch:19, Loss_train:2.68, Loss_test:5.32\n",
            "epoch:20, Loss_train:10.80, Loss_test:6.92\n",
            "epoch:21, Loss_train:20.00, Loss_test:10.18\n",
            "epoch:22, Loss_train:22.93, Loss_test:9.14\n",
            "epoch:23, Loss_train:9.00, Loss_test:10.76\n",
            "epoch:24, Loss_train:11.80, Loss_test:2.23\n",
            "epoch:25, Loss_train:4.77, Loss_test:1.96\n",
            "epoch:26, Loss_train:2.43, Loss_test:1.97\n",
            "epoch:27, Loss_train:2.25, Loss_test:2.64\n",
            "epoch:28, Loss_train:4.76, Loss_test:7.65\n",
            "epoch:29, Loss_train:4.08, Loss_test:4.83\n",
            "epoch:30, Loss_train:12.85, Loss_test:4.98\n",
            "epoch:31, Loss_train:7.29, Loss_test:9.71\n",
            "epoch:32, Loss_train:10.05, Loss_test:4.61\n",
            "epoch:33, Loss_train:9.95, Loss_test:3.08\n",
            "epoch:34, Loss_train:5.76, Loss_test:5.40\n",
            "epoch:35, Loss_train:15.67, Loss_test:2.28\n",
            "epoch:36, Loss_train:2.25, Loss_test:1.26\n",
            "epoch:37, Loss_train:0.38, Loss_test:0.81\n",
            "epoch:38, Loss_train:0.78, Loss_test:0.84\n",
            "epoch:39, Loss_train:0.68, Loss_test:0.80\n",
            "epoch:40, Loss_train:0.51, Loss_test:0.82\n",
            "epoch:41, Loss_train:0.43, Loss_test:0.73\n",
            "epoch:42, Loss_train:0.77, Loss_test:1.09\n",
            "epoch:43, Loss_train:1.84, Loss_test:3.59\n",
            "epoch:44, Loss_train:9.66, Loss_test:3.49\n",
            "epoch:45, Loss_train:5.69, Loss_test:3.08\n",
            "epoch:46, Loss_train:1.20, Loss_test:1.64\n",
            "epoch:47, Loss_train:2.35, Loss_test:1.31\n",
            "epoch:48, Loss_train:1.21, Loss_test:1.68\n",
            "epoch:49, Loss_train:1.25, Loss_test:1.80\n",
            "epoch:50, Loss_train:1.96, Loss_test:1.63\n",
            "epoch:51, Loss_train:2.84, Loss_test:1.63\n",
            "epoch:52, Loss_train:0.47, Loss_test:0.83\n",
            "epoch:53, Loss_train:1.42, Loss_test:0.68\n",
            "epoch:54, Loss_train:1.38, Loss_test:0.68\n",
            "epoch:55, Loss_train:0.44, Loss_test:0.67\n",
            "epoch:56, Loss_train:0.48, Loss_test:0.71\n",
            "epoch:57, Loss_train:1.26, Loss_test:0.72\n",
            "epoch:58, Loss_train:0.43, Loss_test:0.69\n",
            "epoch:59, Loss_train:1.52, Loss_test:0.65\n",
            "epoch:60, Loss_train:0.64, Loss_test:0.67\n",
            "epoch:61, Loss_train:1.56, Loss_test:1.80\n",
            "epoch:62, Loss_train:3.06, Loss_test:3.66\n",
            "epoch:63, Loss_train:4.64, Loss_test:2.94\n",
            "epoch:64, Loss_train:1.71, Loss_test:1.64\n",
            "epoch:65, Loss_train:0.23, Loss_test:0.66\n",
            "epoch:66, Loss_train:0.25, Loss_test:0.61\n",
            "epoch:67, Loss_train:0.43, Loss_test:0.77\n",
            "epoch:68, Loss_train:1.84, Loss_test:1.65\n",
            "epoch:69, Loss_train:1.50, Loss_test:2.55\n",
            "epoch:70, Loss_train:2.24, Loss_test:2.21\n",
            "epoch:71, Loss_train:1.86, Loss_test:1.81\n",
            "epoch:72, Loss_train:2.79, Loss_test:3.00\n",
            "epoch:73, Loss_train:1.04, Loss_test:0.71\n",
            "epoch:74, Loss_train:0.63, Loss_test:0.66\n",
            "epoch:75, Loss_train:1.24, Loss_test:0.59\n",
            "epoch:76, Loss_train:0.60, Loss_test:1.06\n",
            "epoch:77, Loss_train:0.47, Loss_test:0.66\n",
            "epoch:78, Loss_train:1.51, Loss_test:1.15\n",
            "epoch:79, Loss_train:0.31, Loss_test:0.57\n",
            "epoch:80, Loss_train:0.37, Loss_test:0.87\n",
            "epoch:81, Loss_train:0.71, Loss_test:0.99\n",
            "epoch:82, Loss_train:0.20, Loss_test:0.63\n",
            "epoch:83, Loss_train:0.39, Loss_test:0.84\n",
            "epoch:84, Loss_train:1.35, Loss_test:0.59\n",
            "epoch:85, Loss_train:0.55, Loss_test:0.64\n",
            "epoch:86, Loss_train:0.28, Loss_test:0.62\n",
            "epoch:87, Loss_train:0.21, Loss_test:0.56\n",
            "epoch:88, Loss_train:0.32, Loss_test:0.61\n",
            "epoch:89, Loss_train:0.35, Loss_test:0.88\n",
            "epoch:90, Loss_train:1.63, Loss_test:0.94\n",
            "epoch:91, Loss_train:0.40, Loss_test:0.65\n",
            "epoch:92, Loss_train:0.28, Loss_test:0.57\n",
            "epoch:93, Loss_train:0.45, Loss_test:0.60\n",
            "epoch:94, Loss_train:1.20, Loss_test:0.71\n",
            "epoch:95, Loss_train:2.40, Loss_test:1.53\n",
            "epoch:96, Loss_train:0.88, Loss_test:1.46\n",
            "epoch:97, Loss_train:2.20, Loss_test:2.04\n",
            "epoch:98, Loss_train:1.24, Loss_test:1.25\n",
            "epoch:99, Loss_train:0.88, Loss_test:1.77\n",
            "epoch:100, Loss_train:1.78, Loss_test:1.48\n",
            "epoch:101, Loss_train:0.82, Loss_test:1.05\n",
            "epoch:102, Loss_train:0.29, Loss_test:0.58\n",
            "epoch:103, Loss_train:0.30, Loss_test:0.65\n",
            "epoch:104, Loss_train:0.88, Loss_test:0.85\n",
            "epoch:105, Loss_train:0.58, Loss_test:0.83\n",
            "epoch:106, Loss_train:1.69, Loss_test:1.46\n",
            "epoch:107, Loss_train:2.30, Loss_test:3.27\n",
            "epoch:108, Loss_train:1.81, Loss_test:2.59\n",
            "epoch:109, Loss_train:1.16, Loss_test:1.39\n",
            "epoch:110, Loss_train:0.20, Loss_test:0.57\n",
            "epoch:111, Loss_train:1.26, Loss_test:0.62\n",
            "epoch:112, Loss_train:2.35, Loss_test:2.04\n",
            "epoch:113, Loss_train:1.34, Loss_test:1.28\n",
            "epoch:114, Loss_train:2.45, Loss_test:2.15\n",
            "epoch:115, Loss_train:1.44, Loss_test:1.95\n",
            "epoch:116, Loss_train:0.36, Loss_test:0.70\n",
            "epoch:117, Loss_train:0.24, Loss_test:0.57\n",
            "epoch:118, Loss_train:0.60, Loss_test:0.68\n",
            "epoch:119, Loss_train:1.24, Loss_test:0.54\n",
            "epoch:120, Loss_train:2.37, Loss_test:1.50\n",
            "epoch:121, Loss_train:0.65, Loss_test:0.67\n",
            "epoch:122, Loss_train:1.36, Loss_test:1.00\n",
            "epoch:123, Loss_train:0.26, Loss_test:0.59\n",
            "epoch:124, Loss_train:0.42, Loss_test:0.64\n",
            "epoch:125, Loss_train:0.71, Loss_test:1.27\n",
            "epoch:126, Loss_train:0.42, Loss_test:0.53\n",
            "epoch:127, Loss_train:0.84, Loss_test:0.80\n",
            "epoch:128, Loss_train:0.36, Loss_test:0.63\n",
            "epoch:129, Loss_train:0.99, Loss_test:1.39\n",
            "epoch:130, Loss_train:1.84, Loss_test:0.80\n",
            "epoch:131, Loss_train:1.01, Loss_test:0.95\n",
            "epoch:132, Loss_train:1.19, Loss_test:1.54\n",
            "epoch:133, Loss_train:0.36, Loss_test:0.53\n",
            "epoch:134, Loss_train:0.40, Loss_test:0.58\n",
            "epoch:135, Loss_train:0.37, Loss_test:0.59\n",
            "epoch:136, Loss_train:1.17, Loss_test:0.63\n",
            "epoch:137, Loss_train:0.39, Loss_test:0.64\n",
            "epoch:138, Loss_train:0.54, Loss_test:0.93\n",
            "epoch:139, Loss_train:1.03, Loss_test:0.48\n",
            "epoch:140, Loss_train:0.22, Loss_test:0.49\n",
            "epoch:141, Loss_train:0.38, Loss_test:0.73\n",
            "epoch:142, Loss_train:0.79, Loss_test:0.96\n",
            "epoch:143, Loss_train:1.24, Loss_test:0.61\n",
            "epoch:144, Loss_train:0.72, Loss_test:0.91\n",
            "epoch:145, Loss_train:0.97, Loss_test:1.17\n",
            "epoch:146, Loss_train:1.11, Loss_test:1.13\n",
            "epoch:147, Loss_train:0.58, Loss_test:0.56\n",
            "epoch:148, Loss_train:0.24, Loss_test:0.60\n",
            "epoch:149, Loss_train:0.86, Loss_test:0.96\n",
            "epoch:150, Loss_train:0.56, Loss_test:0.93\n",
            "epoch:151, Loss_train:0.55, Loss_test:0.62\n",
            "epoch:152, Loss_train:0.41, Loss_test:0.57\n",
            "epoch:153, Loss_train:0.91, Loss_test:0.53\n",
            "epoch:154, Loss_train:0.39, Loss_test:0.53\n",
            "epoch:155, Loss_train:0.52, Loss_test:0.66\n",
            "epoch:156, Loss_train:0.45, Loss_test:0.61\n",
            "epoch:157, Loss_train:0.29, Loss_test:0.54\n",
            "epoch:158, Loss_train:0.93, Loss_test:0.48\n",
            "epoch:159, Loss_train:0.71, Loss_test:0.70\n",
            "epoch:160, Loss_train:1.02, Loss_test:0.52\n",
            "epoch:161, Loss_train:1.11, Loss_test:0.52\n",
            "epoch:162, Loss_train:0.28, Loss_test:0.54\n",
            "epoch:163, Loss_train:0.42, Loss_test:0.56\n",
            "epoch:164, Loss_train:0.35, Loss_test:0.57\n",
            "epoch:165, Loss_train:0.40, Loss_test:0.50\n",
            "epoch:166, Loss_train:1.14, Loss_test:0.72\n",
            "epoch:167, Loss_train:0.51, Loss_test:0.79\n",
            "epoch:168, Loss_train:1.33, Loss_test:1.18\n",
            "epoch:169, Loss_train:0.30, Loss_test:0.51\n",
            "epoch:170, Loss_train:0.38, Loss_test:0.50\n",
            "epoch:171, Loss_train:0.40, Loss_test:0.73\n",
            "epoch:172, Loss_train:0.54, Loss_test:0.56\n",
            "epoch:173, Loss_train:0.30, Loss_test:0.50\n",
            "epoch:174, Loss_train:0.33, Loss_test:0.49\n",
            "epoch:175, Loss_train:0.24, Loss_test:0.60\n",
            "epoch:176, Loss_train:0.21, Loss_test:0.48\n",
            "epoch:177, Loss_train:0.18, Loss_test:0.51\n",
            "epoch:178, Loss_train:0.23, Loss_test:0.46\n",
            "epoch:179, Loss_train:0.76, Loss_test:0.55\n",
            "epoch:180, Loss_train:0.68, Loss_test:0.78\n",
            "epoch:181, Loss_train:0.69, Loss_test:0.90\n",
            "epoch:182, Loss_train:0.89, Loss_test:0.47\n",
            "epoch:183, Loss_train:0.92, Loss_test:0.49\n",
            "epoch:184, Loss_train:0.46, Loss_test:0.63\n",
            "epoch:185, Loss_train:1.16, Loss_test:0.74\n",
            "epoch:186, Loss_train:1.02, Loss_test:0.58\n",
            "epoch:187, Loss_train:0.62, Loss_test:0.71\n",
            "epoch:188, Loss_train:1.61, Loss_test:1.63\n",
            "epoch:189, Loss_train:0.67, Loss_test:0.73\n",
            "epoch:190, Loss_train:0.58, Loss_test:0.78\n",
            "epoch:191, Loss_train:1.17, Loss_test:0.88\n",
            "epoch:192, Loss_train:0.41, Loss_test:0.55\n",
            "epoch:193, Loss_train:0.23, Loss_test:0.43\n",
            "epoch:194, Loss_train:0.33, Loss_test:0.62\n",
            "epoch:195, Loss_train:0.96, Loss_test:0.43\n",
            "epoch:196, Loss_train:0.41, Loss_test:0.54\n",
            "epoch:197, Loss_train:0.96, Loss_test:0.43\n",
            "epoch:198, Loss_train:0.34, Loss_test:0.46\n",
            "epoch:199, Loss_train:0.99, Loss_test:0.42\n",
            "epoch:200, Loss_train:0.17, Loss_test:0.53\n",
            "epoch:201, Loss_train:0.30, Loss_test:0.46\n",
            "epoch:202, Loss_train:0.29, Loss_test:0.49\n",
            "epoch:203, Loss_train:0.39, Loss_test:0.53\n",
            "epoch:204, Loss_train:0.36, Loss_test:0.42\n",
            "epoch:205, Loss_train:0.48, Loss_test:0.59\n",
            "epoch:206, Loss_train:0.65, Loss_test:0.97\n",
            "epoch:207, Loss_train:1.68, Loss_test:1.10\n",
            "epoch:208, Loss_train:0.64, Loss_test:1.06\n",
            "epoch:209, Loss_train:0.64, Loss_test:0.52\n",
            "epoch:210, Loss_train:0.31, Loss_test:0.47\n",
            "epoch:211, Loss_train:0.16, Loss_test:0.42\n",
            "epoch:212, Loss_train:0.35, Loss_test:0.43\n",
            "epoch:213, Loss_train:1.04, Loss_test:0.63\n",
            "epoch:214, Loss_train:0.87, Loss_test:0.41\n",
            "epoch:215, Loss_train:0.21, Loss_test:0.44\n",
            "epoch:216, Loss_train:0.50, Loss_test:0.72\n",
            "epoch:217, Loss_train:0.32, Loss_test:0.47\n",
            "epoch:218, Loss_train:0.34, Loss_test:0.54\n",
            "epoch:219, Loss_train:0.77, Loss_test:0.45\n",
            "epoch:220, Loss_train:0.30, Loss_test:0.46\n",
            "epoch:221, Loss_train:0.97, Loss_test:0.49\n",
            "epoch:222, Loss_train:0.18, Loss_test:0.42\n",
            "epoch:223, Loss_train:0.34, Loss_test:0.74\n",
            "epoch:224, Loss_train:0.15, Loss_test:0.41\n",
            "epoch:225, Loss_train:0.58, Loss_test:0.58\n",
            "epoch:226, Loss_train:0.19, Loss_test:0.44\n",
            "epoch:227, Loss_train:0.19, Loss_test:0.43\n",
            "epoch:228, Loss_train:0.20, Loss_test:0.43\n",
            "epoch:229, Loss_train:0.28, Loss_test:0.49\n",
            "epoch:230, Loss_train:0.83, Loss_test:1.43\n",
            "epoch:231, Loss_train:1.26, Loss_test:0.53\n",
            "epoch:232, Loss_train:0.26, Loss_test:0.41\n",
            "epoch:233, Loss_train:0.34, Loss_test:0.40\n",
            "epoch:234, Loss_train:0.28, Loss_test:0.46\n",
            "epoch:235, Loss_train:0.81, Loss_test:0.43\n",
            "epoch:236, Loss_train:0.22, Loss_test:0.53\n",
            "epoch:237, Loss_train:0.62, Loss_test:0.61\n",
            "epoch:238, Loss_train:0.60, Loss_test:0.58\n",
            "epoch:239, Loss_train:0.78, Loss_test:0.44\n",
            "epoch:240, Loss_train:0.31, Loss_test:0.43\n",
            "epoch:241, Loss_train:0.28, Loss_test:0.48\n",
            "epoch:242, Loss_train:0.20, Loss_test:0.53\n",
            "epoch:243, Loss_train:0.20, Loss_test:0.46\n",
            "epoch:244, Loss_train:0.39, Loss_test:0.60\n",
            "epoch:245, Loss_train:0.57, Loss_test:0.67\n",
            "epoch:246, Loss_train:0.56, Loss_test:0.65\n",
            "epoch:247, Loss_train:0.40, Loss_test:0.53\n",
            "epoch:248, Loss_train:1.22, Loss_test:0.98\n",
            "epoch:249, Loss_train:0.83, Loss_test:1.00\n",
            "epoch:250, Loss_train:0.77, Loss_test:0.56\n",
            "epoch:251, Loss_train:1.66, Loss_test:1.30\n",
            "epoch:252, Loss_train:1.41, Loss_test:1.03\n",
            "epoch:253, Loss_train:0.34, Loss_test:0.42\n",
            "epoch:254, Loss_train:0.83, Loss_test:0.51\n",
            "epoch:255, Loss_train:0.42, Loss_test:0.71\n",
            "epoch:256, Loss_train:0.36, Loss_test:0.83\n",
            "epoch:257, Loss_train:0.25, Loss_test:0.46\n",
            "epoch:258, Loss_train:0.31, Loss_test:0.40\n",
            "epoch:259, Loss_train:0.29, Loss_test:0.64\n",
            "epoch:260, Loss_train:0.29, Loss_test:0.38\n",
            "epoch:261, Loss_train:0.81, Loss_test:0.39\n",
            "epoch:262, Loss_train:0.78, Loss_test:0.43\n",
            "epoch:263, Loss_train:0.30, Loss_test:0.38\n",
            "epoch:264, Loss_train:0.16, Loss_test:0.42\n",
            "epoch:265, Loss_train:0.74, Loss_test:0.38\n",
            "epoch:266, Loss_train:0.23, Loss_test:0.37\n",
            "epoch:267, Loss_train:0.18, Loss_test:0.39\n",
            "epoch:268, Loss_train:0.23, Loss_test:0.42\n",
            "epoch:269, Loss_train:0.75, Loss_test:0.38\n",
            "epoch:270, Loss_train:0.19, Loss_test:0.46\n",
            "epoch:271, Loss_train:0.31, Loss_test:0.49\n",
            "epoch:272, Loss_train:0.31, Loss_test:0.56\n",
            "epoch:273, Loss_train:0.43, Loss_test:0.41\n",
            "epoch:274, Loss_train:0.32, Loss_test:0.50\n",
            "epoch:275, Loss_train:0.19, Loss_test:0.39\n",
            "epoch:276, Loss_train:0.16, Loss_test:0.40\n",
            "epoch:277, Loss_train:0.29, Loss_test:0.52\n",
            "epoch:278, Loss_train:0.41, Loss_test:0.58\n",
            "epoch:279, Loss_train:0.25, Loss_test:0.48\n",
            "epoch:280, Loss_train:0.15, Loss_test:0.38\n",
            "epoch:281, Loss_train:0.12, Loss_test:0.40\n",
            "epoch:282, Loss_train:0.35, Loss_test:0.50\n",
            "epoch:283, Loss_train:0.21, Loss_test:0.42\n",
            "epoch:284, Loss_train:0.49, Loss_test:0.58\n",
            "epoch:285, Loss_train:0.38, Loss_test:0.71\n",
            "epoch:286, Loss_train:0.46, Loss_test:0.65\n",
            "epoch:287, Loss_train:1.06, Loss_test:0.90\n",
            "epoch:288, Loss_train:0.18, Loss_test:0.41\n",
            "epoch:289, Loss_train:0.82, Loss_test:0.39\n",
            "epoch:290, Loss_train:0.11, Loss_test:0.40\n",
            "epoch:291, Loss_train:0.25, Loss_test:0.38\n",
            "epoch:292, Loss_train:0.28, Loss_test:0.43\n",
            "epoch:293, Loss_train:0.26, Loss_test:0.38\n",
            "epoch:294, Loss_train:0.16, Loss_test:0.37\n",
            "epoch:295, Loss_train:0.63, Loss_test:0.38\n",
            "epoch:296, Loss_train:0.21, Loss_test:0.40\n",
            "epoch:297, Loss_train:0.29, Loss_test:0.52\n",
            "epoch:298, Loss_train:0.17, Loss_test:0.37\n",
            "epoch:299, Loss_train:0.26, Loss_test:0.46\n",
            "epoch:300, Loss_train:0.68, Loss_test:0.38\n",
            "epoch:301, Loss_train:0.64, Loss_test:0.42\n",
            "epoch:302, Loss_train:0.28, Loss_test:0.42\n",
            "epoch:303, Loss_train:0.20, Loss_test:0.44\n",
            "epoch:304, Loss_train:0.78, Loss_test:0.48\n",
            "epoch:305, Loss_train:0.29, Loss_test:0.51\n",
            "epoch:306, Loss_train:0.41, Loss_test:0.53\n",
            "epoch:307, Loss_train:0.44, Loss_test:0.50\n",
            "epoch:308, Loss_train:0.09, Loss_test:0.39\n",
            "epoch:309, Loss_train:0.78, Loss_test:0.43\n",
            "epoch:310, Loss_train:0.24, Loss_test:0.42\n",
            "epoch:311, Loss_train:0.18, Loss_test:0.36\n",
            "epoch:312, Loss_train:0.21, Loss_test:0.53\n",
            "epoch:313, Loss_train:0.49, Loss_test:0.60\n",
            "epoch:314, Loss_train:0.13, Loss_test:0.38\n",
            "epoch:315, Loss_train:0.20, Loss_test:0.43\n",
            "epoch:316, Loss_train:0.23, Loss_test:0.41\n",
            "epoch:317, Loss_train:0.18, Loss_test:0.42\n",
            "epoch:318, Loss_train:0.13, Loss_test:0.38\n",
            "epoch:319, Loss_train:0.16, Loss_test:0.37\n",
            "epoch:320, Loss_train:0.61, Loss_test:0.37\n",
            "epoch:321, Loss_train:0.16, Loss_test:0.42\n",
            "epoch:322, Loss_train:0.24, Loss_test:0.42\n",
            "epoch:323, Loss_train:0.25, Loss_test:0.48\n",
            "epoch:324, Loss_train:0.16, Loss_test:0.37\n",
            "epoch:325, Loss_train:0.80, Loss_test:0.54\n",
            "epoch:326, Loss_train:0.22, Loss_test:0.37\n",
            "epoch:327, Loss_train:0.63, Loss_test:0.50\n",
            "epoch:328, Loss_train:0.14, Loss_test:0.37\n",
            "epoch:329, Loss_train:0.29, Loss_test:0.46\n",
            "epoch:330, Loss_train:0.77, Loss_test:0.63\n",
            "epoch:331, Loss_train:0.14, Loss_test:0.37\n",
            "epoch:332, Loss_train:0.19, Loss_test:0.41\n",
            "epoch:333, Loss_train:0.15, Loss_test:0.36\n",
            "epoch:334, Loss_train:0.25, Loss_test:0.40\n",
            "epoch:335, Loss_train:0.85, Loss_test:0.77\n",
            "epoch:336, Loss_train:0.81, Loss_test:0.61\n",
            "epoch:337, Loss_train:0.22, Loss_test:0.38\n",
            "epoch:338, Loss_train:0.58, Loss_test:0.37\n",
            "epoch:339, Loss_train:0.21, Loss_test:0.38\n",
            "epoch:340, Loss_train:0.60, Loss_test:0.43\n",
            "epoch:341, Loss_train:0.55, Loss_test:0.48\n",
            "epoch:342, Loss_train:0.28, Loss_test:0.46\n",
            "epoch:343, Loss_train:0.26, Loss_test:0.48\n",
            "epoch:344, Loss_train:0.18, Loss_test:0.39\n",
            "epoch:345, Loss_train:0.23, Loss_test:0.40\n",
            "epoch:346, Loss_train:0.22, Loss_test:0.37\n",
            "epoch:347, Loss_train:0.27, Loss_test:0.46\n",
            "epoch:348, Loss_train:0.40, Loss_test:0.85\n",
            "epoch:349, Loss_train:0.28, Loss_test:0.46\n",
            "epoch:350, Loss_train:0.24, Loss_test:0.41\n",
            "epoch:351, Loss_train:0.14, Loss_test:0.35\n",
            "epoch:352, Loss_train:0.24, Loss_test:0.37\n",
            "epoch:353, Loss_train:0.16, Loss_test:0.37\n",
            "epoch:354, Loss_train:0.17, Loss_test:0.39\n",
            "epoch:355, Loss_train:0.12, Loss_test:0.41\n",
            "epoch:356, Loss_train:0.21, Loss_test:0.37\n",
            "epoch:357, Loss_train:0.10, Loss_test:0.36\n",
            "epoch:358, Loss_train:0.56, Loss_test:0.39\n",
            "epoch:359, Loss_train:0.17, Loss_test:0.36\n",
            "epoch:360, Loss_train:0.53, Loss_test:0.45\n",
            "epoch:361, Loss_train:0.61, Loss_test:0.61\n",
            "epoch:362, Loss_train:0.48, Loss_test:0.89\n",
            "epoch:363, Loss_train:0.13, Loss_test:0.36\n",
            "epoch:364, Loss_train:0.24, Loss_test:0.41\n",
            "epoch:365, Loss_train:0.20, Loss_test:0.42\n",
            "epoch:366, Loss_train:0.15, Loss_test:0.38\n",
            "epoch:367, Loss_train:0.22, Loss_test:0.47\n",
            "epoch:368, Loss_train:0.56, Loss_test:0.49\n",
            "epoch:369, Loss_train:0.30, Loss_test:0.43\n",
            "epoch:370, Loss_train:0.37, Loss_test:0.46\n",
            "epoch:371, Loss_train:0.48, Loss_test:0.57\n",
            "epoch:372, Loss_train:0.17, Loss_test:0.42\n",
            "epoch:373, Loss_train:0.37, Loss_test:0.48\n",
            "epoch:374, Loss_train:0.17, Loss_test:0.34\n",
            "epoch:375, Loss_train:0.60, Loss_test:0.57\n",
            "epoch:376, Loss_train:0.31, Loss_test:0.53\n",
            "epoch:377, Loss_train:0.51, Loss_test:0.44\n",
            "epoch:378, Loss_train:0.51, Loss_test:0.42\n",
            "epoch:379, Loss_train:0.69, Loss_test:0.43\n",
            "epoch:380, Loss_train:0.20, Loss_test:0.36\n",
            "epoch:381, Loss_train:0.12, Loss_test:0.39\n",
            "epoch:382, Loss_train:0.24, Loss_test:0.34\n",
            "epoch:383, Loss_train:0.12, Loss_test:0.36\n",
            "epoch:384, Loss_train:0.35, Loss_test:0.52\n",
            "epoch:385, Loss_train:0.14, Loss_test:0.40\n",
            "epoch:386, Loss_train:0.15, Loss_test:0.39\n",
            "epoch:387, Loss_train:0.58, Loss_test:0.35\n",
            "epoch:388, Loss_train:0.19, Loss_test:0.36\n",
            "epoch:389, Loss_train:0.52, Loss_test:0.37\n",
            "epoch:390, Loss_train:0.19, Loss_test:0.41\n",
            "epoch:391, Loss_train:0.27, Loss_test:0.46\n",
            "epoch:392, Loss_train:0.64, Loss_test:0.64\n",
            "epoch:393, Loss_train:0.71, Loss_test:0.54\n",
            "epoch:394, Loss_train:0.21, Loss_test:0.42\n",
            "epoch:395, Loss_train:0.47, Loss_test:0.38\n",
            "epoch:396, Loss_train:0.67, Loss_test:0.54\n",
            "epoch:397, Loss_train:0.20, Loss_test:0.48\n",
            "epoch:398, Loss_train:0.30, Loss_test:0.64\n",
            "epoch:399, Loss_train:0.37, Loss_test:0.57\n",
            "epoch:400, Loss_train:0.16, Loss_test:0.38\n",
            "epoch:401, Loss_train:0.31, Loss_test:0.55\n",
            "epoch:402, Loss_train:0.17, Loss_test:0.36\n",
            "epoch:403, Loss_train:0.54, Loss_test:0.37\n",
            "epoch:404, Loss_train:0.25, Loss_test:0.44\n",
            "epoch:405, Loss_train:0.31, Loss_test:0.40\n",
            "epoch:406, Loss_train:0.24, Loss_test:0.42\n",
            "epoch:407, Loss_train:0.18, Loss_test:0.38\n",
            "epoch:408, Loss_train:0.49, Loss_test:0.36\n",
            "epoch:409, Loss_train:0.47, Loss_test:0.46\n",
            "epoch:410, Loss_train:0.16, Loss_test:0.37\n",
            "epoch:411, Loss_train:0.23, Loss_test:0.45\n",
            "epoch:412, Loss_train:0.58, Loss_test:0.47\n",
            "epoch:413, Loss_train:0.39, Loss_test:0.66\n",
            "epoch:414, Loss_train:1.21, Loss_test:1.13\n",
            "epoch:415, Loss_train:0.93, Loss_test:1.36\n",
            "epoch:416, Loss_train:1.51, Loss_test:0.92\n",
            "epoch:417, Loss_train:0.33, Loss_test:0.39\n",
            "epoch:418, Loss_train:0.41, Loss_test:0.52\n",
            "epoch:419, Loss_train:0.28, Loss_test:0.39\n",
            "epoch:420, Loss_train:0.15, Loss_test:0.42\n",
            "epoch:421, Loss_train:0.17, Loss_test:0.37\n",
            "epoch:422, Loss_train:0.15, Loss_test:0.43\n",
            "epoch:423, Loss_train:0.18, Loss_test:0.37\n",
            "epoch:424, Loss_train:0.23, Loss_test:0.39\n",
            "epoch:425, Loss_train:0.20, Loss_test:0.47\n",
            "epoch:426, Loss_train:0.71, Loss_test:0.64\n",
            "epoch:427, Loss_train:0.28, Loss_test:0.37\n",
            "epoch:428, Loss_train:0.11, Loss_test:0.36\n",
            "epoch:429, Loss_train:0.16, Loss_test:0.38\n",
            "epoch:430, Loss_train:0.27, Loss_test:0.50\n",
            "epoch:431, Loss_train:0.54, Loss_test:0.58\n",
            "epoch:432, Loss_train:0.23, Loss_test:0.44\n",
            "epoch:433, Loss_train:0.30, Loss_test:0.46\n",
            "epoch:434, Loss_train:0.40, Loss_test:0.36\n",
            "epoch:435, Loss_train:0.27, Loss_test:0.42\n",
            "epoch:436, Loss_train:0.22, Loss_test:0.51\n",
            "epoch:437, Loss_train:0.24, Loss_test:0.47\n",
            "epoch:438, Loss_train:0.33, Loss_test:0.48\n",
            "epoch:439, Loss_train:0.45, Loss_test:0.41\n",
            "epoch:440, Loss_train:0.13, Loss_test:0.38\n",
            "epoch:441, Loss_train:0.54, Loss_test:0.65\n",
            "epoch:442, Loss_train:0.16, Loss_test:0.46\n",
            "epoch:443, Loss_train:0.14, Loss_test:0.44\n",
            "epoch:444, Loss_train:0.19, Loss_test:0.39\n",
            "epoch:445, Loss_train:0.48, Loss_test:0.41\n",
            "epoch:446, Loss_train:0.16, Loss_test:0.43\n",
            "epoch:447, Loss_train:0.22, Loss_test:0.42\n",
            "epoch:448, Loss_train:0.30, Loss_test:0.46\n",
            "epoch:449, Loss_train:0.26, Loss_test:0.59\n",
            "epoch:450, Loss_train:0.17, Loss_test:0.41\n",
            "epoch:451, Loss_train:0.09, Loss_test:0.38\n",
            "epoch:452, Loss_train:0.35, Loss_test:0.38\n",
            "epoch:453, Loss_train:0.21, Loss_test:0.45\n",
            "epoch:454, Loss_train:0.17, Loss_test:0.42\n",
            "epoch:455, Loss_train:0.12, Loss_test:0.42\n",
            "epoch:456, Loss_train:0.19, Loss_test:0.44\n",
            "epoch:457, Loss_train:0.38, Loss_test:0.37\n",
            "epoch:458, Loss_train:0.26, Loss_test:0.52\n",
            "epoch:459, Loss_train:0.39, Loss_test:0.42\n",
            "epoch:460, Loss_train:0.15, Loss_test:0.42\n",
            "epoch:461, Loss_train:0.11, Loss_test:0.37\n",
            "epoch:462, Loss_train:0.37, Loss_test:0.38\n",
            "epoch:463, Loss_train:0.31, Loss_test:0.49\n",
            "epoch:464, Loss_train:0.63, Loss_test:0.74\n",
            "epoch:465, Loss_train:0.45, Loss_test:0.68\n",
            "epoch:466, Loss_train:0.29, Loss_test:0.47\n",
            "epoch:467, Loss_train:0.73, Loss_test:0.58\n",
            "epoch:468, Loss_train:0.16, Loss_test:0.40\n",
            "epoch:469, Loss_train:0.51, Loss_test:0.45\n",
            "epoch:470, Loss_train:0.15, Loss_test:0.38\n",
            "epoch:471, Loss_train:0.37, Loss_test:0.40\n",
            "epoch:472, Loss_train:0.17, Loss_test:0.39\n",
            "epoch:473, Loss_train:0.51, Loss_test:0.61\n",
            "epoch:474, Loss_train:0.53, Loss_test:0.63\n",
            "epoch:475, Loss_train:0.37, Loss_test:0.42\n",
            "epoch:476, Loss_train:0.22, Loss_test:0.45\n",
            "epoch:477, Loss_train:0.16, Loss_test:0.43\n",
            "epoch:478, Loss_train:0.63, Loss_test:0.76\n",
            "epoch:479, Loss_train:1.06, Loss_test:1.26\n",
            "epoch:480, Loss_train:0.24, Loss_test:0.47\n",
            "epoch:481, Loss_train:0.20, Loss_test:0.37\n",
            "epoch:482, Loss_train:0.14, Loss_test:0.37\n",
            "epoch:483, Loss_train:0.45, Loss_test:0.45\n",
            "epoch:484, Loss_train:0.14, Loss_test:0.36\n",
            "epoch:485, Loss_train:0.36, Loss_test:0.39\n",
            "epoch:486, Loss_train:0.29, Loss_test:0.45\n",
            "epoch:487, Loss_train:0.13, Loss_test:0.36\n",
            "epoch:488, Loss_train:0.44, Loss_test:0.40\n",
            "epoch:489, Loss_train:0.36, Loss_test:0.41\n",
            "epoch:490, Loss_train:0.20, Loss_test:0.48\n",
            "epoch:491, Loss_train:0.36, Loss_test:0.40\n",
            "epoch:492, Loss_train:0.36, Loss_test:0.38\n",
            "epoch:493, Loss_train:0.70, Loss_test:0.73\n",
            "epoch:494, Loss_train:0.18, Loss_test:0.38\n",
            "epoch:495, Loss_train:0.10, Loss_test:0.39\n",
            "epoch:496, Loss_train:0.16, Loss_test:0.37\n",
            "epoch:497, Loss_train:0.42, Loss_test:0.41\n",
            "epoch:498, Loss_train:0.15, Loss_test:0.36\n",
            "epoch:499, Loss_train:0.14, Loss_test:0.41\n",
            "epoch:500, Loss_train:0.17, Loss_test:0.37\n",
            "epoch:501, Loss_train:0.11, Loss_test:0.37\n",
            "epoch:502, Loss_train:0.14, Loss_test:0.37\n",
            "epoch:503, Loss_train:0.39, Loss_test:0.39\n",
            "epoch:504, Loss_train:0.23, Loss_test:0.49\n",
            "epoch:505, Loss_train:0.20, Loss_test:0.40\n",
            "epoch:506, Loss_train:0.32, Loss_test:0.59\n",
            "epoch:507, Loss_train:0.27, Loss_test:0.62\n",
            "epoch:508, Loss_train:0.31, Loss_test:0.41\n",
            "epoch:509, Loss_train:0.23, Loss_test:0.41\n",
            "epoch:510, Loss_train:0.11, Loss_test:0.37\n",
            "epoch:511, Loss_train:0.15, Loss_test:0.36\n",
            "epoch:512, Loss_train:0.10, Loss_test:0.39\n",
            "epoch:513, Loss_train:0.46, Loss_test:0.83\n",
            "epoch:514, Loss_train:0.34, Loss_test:0.60\n",
            "epoch:515, Loss_train:0.81, Loss_test:1.04\n",
            "epoch:516, Loss_train:0.63, Loss_test:0.64\n",
            "epoch:517, Loss_train:0.32, Loss_test:0.53\n",
            "epoch:518, Loss_train:0.26, Loss_test:0.46\n",
            "epoch:519, Loss_train:0.14, Loss_test:0.39\n",
            "epoch:520, Loss_train:0.11, Loss_test:0.36\n",
            "epoch:521, Loss_train:0.20, Loss_test:0.49\n",
            "epoch:522, Loss_train:0.15, Loss_test:0.42\n",
            "epoch:523, Loss_train:0.12, Loss_test:0.35\n",
            "epoch:524, Loss_train:0.40, Loss_test:0.42\n",
            "epoch:525, Loss_train:0.13, Loss_test:0.36\n",
            "epoch:526, Loss_train:0.18, Loss_test:0.38\n",
            "epoch:527, Loss_train:0.29, Loss_test:0.48\n",
            "epoch:528, Loss_train:0.15, Loss_test:0.38\n",
            "epoch:529, Loss_train:0.39, Loss_test:0.48\n",
            "epoch:530, Loss_train:0.20, Loss_test:0.38\n",
            "epoch:531, Loss_train:0.20, Loss_test:0.40\n",
            "epoch:532, Loss_train:0.15, Loss_test:0.39\n",
            "epoch:533, Loss_train:0.37, Loss_test:0.38\n",
            "epoch:534, Loss_train:0.10, Loss_test:0.40\n",
            "epoch:535, Loss_train:0.30, Loss_test:0.44\n",
            "epoch:536, Loss_train:0.09, Loss_test:0.36\n",
            "epoch:537, Loss_train:0.23, Loss_test:0.42\n",
            "epoch:538, Loss_train:0.30, Loss_test:0.40\n",
            "epoch:539, Loss_train:0.15, Loss_test:0.35\n",
            "epoch:540, Loss_train:0.36, Loss_test:0.43\n",
            "epoch:541, Loss_train:0.23, Loss_test:0.37\n",
            "epoch:542, Loss_train:0.20, Loss_test:0.43\n",
            "epoch:543, Loss_train:0.15, Loss_test:0.40\n",
            "epoch:544, Loss_train:0.25, Loss_test:0.59\n",
            "epoch:545, Loss_train:0.40, Loss_test:0.70\n",
            "epoch:546, Loss_train:0.23, Loss_test:0.58\n",
            "epoch:547, Loss_train:0.10, Loss_test:0.35\n",
            "epoch:548, Loss_train:0.38, Loss_test:0.54\n",
            "epoch:549, Loss_train:0.11, Loss_test:0.35\n",
            "epoch:550, Loss_train:0.15, Loss_test:0.36\n",
            "epoch:551, Loss_train:0.22, Loss_test:0.43\n",
            "epoch:552, Loss_train:0.16, Loss_test:0.38\n",
            "epoch:553, Loss_train:0.14, Loss_test:0.36\n",
            "epoch:554, Loss_train:0.14, Loss_test:0.41\n",
            "epoch:555, Loss_train:0.21, Loss_test:0.35\n",
            "epoch:556, Loss_train:0.28, Loss_test:0.36\n",
            "epoch:557, Loss_train:0.15, Loss_test:0.38\n",
            "epoch:558, Loss_train:0.11, Loss_test:0.35\n",
            "epoch:559, Loss_train:0.12, Loss_test:0.34\n",
            "epoch:560, Loss_train:0.22, Loss_test:0.42\n",
            "epoch:561, Loss_train:0.36, Loss_test:0.57\n",
            "epoch:562, Loss_train:0.14, Loss_test:0.39\n",
            "epoch:563, Loss_train:0.22, Loss_test:0.49\n",
            "epoch:564, Loss_train:0.25, Loss_test:0.39\n",
            "epoch:565, Loss_train:0.17, Loss_test:0.40\n",
            "epoch:566, Loss_train:0.45, Loss_test:0.64\n",
            "epoch:567, Loss_train:0.43, Loss_test:0.45\n",
            "epoch:568, Loss_train:0.14, Loss_test:0.40\n",
            "epoch:569, Loss_train:0.39, Loss_test:0.47\n",
            "epoch:570, Loss_train:0.33, Loss_test:0.77\n",
            "epoch:571, Loss_train:0.72, Loss_test:0.85\n",
            "epoch:572, Loss_train:0.84, Loss_test:0.89\n",
            "epoch:573, Loss_train:0.17, Loss_test:0.40\n",
            "epoch:574, Loss_train:0.34, Loss_test:0.40\n",
            "epoch:575, Loss_train:0.13, Loss_test:0.36\n",
            "epoch:576, Loss_train:0.23, Loss_test:0.38\n",
            "epoch:577, Loss_train:0.20, Loss_test:0.52\n",
            "epoch:578, Loss_train:0.27, Loss_test:0.37\n",
            "epoch:579, Loss_train:0.14, Loss_test:0.34\n",
            "epoch:580, Loss_train:0.17, Loss_test:0.35\n",
            "epoch:581, Loss_train:0.29, Loss_test:0.37\n",
            "epoch:582, Loss_train:0.25, Loss_test:0.50\n",
            "epoch:583, Loss_train:0.20, Loss_test:0.44\n",
            "epoch:584, Loss_train:0.15, Loss_test:0.45\n",
            "epoch:585, Loss_train:0.22, Loss_test:0.36\n",
            "epoch:586, Loss_train:0.25, Loss_test:0.45\n",
            "epoch:587, Loss_train:0.13, Loss_test:0.35\n",
            "epoch:588, Loss_train:0.39, Loss_test:0.42\n",
            "epoch:589, Loss_train:0.33, Loss_test:0.38\n",
            "epoch:590, Loss_train:0.20, Loss_test:0.41\n",
            "epoch:591, Loss_train:0.59, Loss_test:0.63\n",
            "epoch:592, Loss_train:0.49, Loss_test:0.73\n",
            "epoch:593, Loss_train:0.45, Loss_test:0.76\n",
            "epoch:594, Loss_train:0.28, Loss_test:0.38\n",
            "epoch:595, Loss_train:0.43, Loss_test:0.47\n",
            "epoch:596, Loss_train:0.37, Loss_test:0.49\n",
            "epoch:597, Loss_train:0.29, Loss_test:0.45\n",
            "epoch:598, Loss_train:0.12, Loss_test:0.37\n",
            "epoch:599, Loss_train:0.14, Loss_test:0.38\n",
            "epoch:600, Loss_train:0.28, Loss_test:0.37\n",
            "epoch:601, Loss_train:0.27, Loss_test:0.40\n",
            "epoch:602, Loss_train:0.23, Loss_test:0.44\n",
            "epoch:603, Loss_train:0.19, Loss_test:0.36\n",
            "epoch:604, Loss_train:0.30, Loss_test:0.39\n",
            "epoch:605, Loss_train:0.25, Loss_test:0.44\n",
            "epoch:606, Loss_train:0.15, Loss_test:0.35\n",
            "epoch:607, Loss_train:0.14, Loss_test:0.35\n",
            "epoch:608, Loss_train:0.16, Loss_test:0.35\n",
            "epoch:609, Loss_train:0.10, Loss_test:0.35\n",
            "epoch:610, Loss_train:0.17, Loss_test:0.34\n",
            "epoch:611, Loss_train:0.11, Loss_test:0.34\n",
            "epoch:612, Loss_train:0.11, Loss_test:0.35\n",
            "epoch:613, Loss_train:0.27, Loss_test:0.43\n",
            "epoch:614, Loss_train:0.13, Loss_test:0.35\n",
            "epoch:615, Loss_train:0.14, Loss_test:0.39\n",
            "epoch:616, Loss_train:0.37, Loss_test:0.49\n",
            "epoch:617, Loss_train:0.16, Loss_test:0.42\n",
            "epoch:618, Loss_train:0.11, Loss_test:0.33\n",
            "epoch:619, Loss_train:0.38, Loss_test:0.44\n",
            "epoch:620, Loss_train:0.44, Loss_test:0.59\n",
            "epoch:621, Loss_train:0.19, Loss_test:0.48\n",
            "epoch:622, Loss_train:0.10, Loss_test:0.34\n",
            "epoch:623, Loss_train:0.12, Loss_test:0.36\n",
            "epoch:624, Loss_train:0.24, Loss_test:0.40\n",
            "epoch:625, Loss_train:0.18, Loss_test:0.36\n",
            "epoch:626, Loss_train:0.19, Loss_test:0.43\n",
            "epoch:627, Loss_train:0.31, Loss_test:0.37\n",
            "epoch:628, Loss_train:0.25, Loss_test:0.40\n",
            "epoch:629, Loss_train:0.13, Loss_test:0.34\n",
            "epoch:630, Loss_train:0.13, Loss_test:0.37\n",
            "epoch:631, Loss_train:0.42, Loss_test:0.73\n",
            "epoch:632, Loss_train:0.34, Loss_test:0.86\n",
            "epoch:633, Loss_train:0.33, Loss_test:0.40\n",
            "epoch:634, Loss_train:0.20, Loss_test:0.46\n",
            "epoch:635, Loss_train:0.17, Loss_test:0.36\n",
            "epoch:636, Loss_train:0.11, Loss_test:0.34\n",
            "epoch:637, Loss_train:0.12, Loss_test:0.38\n",
            "epoch:638, Loss_train:0.14, Loss_test:0.35\n",
            "epoch:639, Loss_train:0.21, Loss_test:0.38\n",
            "epoch:640, Loss_train:0.10, Loss_test:0.33\n",
            "epoch:641, Loss_train:0.12, Loss_test:0.37\n",
            "epoch:642, Loss_train:0.29, Loss_test:0.37\n",
            "epoch:643, Loss_train:0.27, Loss_test:0.37\n",
            "epoch:644, Loss_train:0.27, Loss_test:0.38\n",
            "epoch:645, Loss_train:0.15, Loss_test:0.40\n",
            "epoch:646, Loss_train:0.15, Loss_test:0.33\n",
            "epoch:647, Loss_train:0.10, Loss_test:0.34\n",
            "epoch:648, Loss_train:0.10, Loss_test:0.33\n",
            "epoch:649, Loss_train:0.25, Loss_test:0.41\n",
            "epoch:650, Loss_train:0.23, Loss_test:0.40\n",
            "epoch:651, Loss_train:0.34, Loss_test:0.60\n",
            "epoch:652, Loss_train:0.16, Loss_test:0.34\n",
            "epoch:653, Loss_train:0.14, Loss_test:0.33\n",
            "epoch:654, Loss_train:0.28, Loss_test:0.34\n",
            "epoch:655, Loss_train:0.25, Loss_test:0.35\n",
            "epoch:656, Loss_train:0.28, Loss_test:0.50\n",
            "epoch:657, Loss_train:0.19, Loss_test:0.44\n",
            "epoch:658, Loss_train:0.16, Loss_test:0.37\n",
            "epoch:659, Loss_train:0.27, Loss_test:0.38\n",
            "epoch:660, Loss_train:0.16, Loss_test:0.37\n",
            "epoch:661, Loss_train:0.30, Loss_test:0.54\n",
            "epoch:662, Loss_train:0.22, Loss_test:0.45\n",
            "epoch:663, Loss_train:0.25, Loss_test:0.38\n",
            "epoch:664, Loss_train:0.21, Loss_test:0.34\n",
            "epoch:665, Loss_train:0.16, Loss_test:0.33\n",
            "epoch:666, Loss_train:0.16, Loss_test:0.32\n",
            "epoch:667, Loss_train:0.28, Loss_test:0.37\n",
            "epoch:668, Loss_train:0.18, Loss_test:0.44\n",
            "epoch:669, Loss_train:0.68, Loss_test:0.94\n",
            "epoch:670, Loss_train:1.03, Loss_test:0.56\n",
            "epoch:671, Loss_train:0.12, Loss_test:0.35\n",
            "epoch:672, Loss_train:0.25, Loss_test:0.40\n",
            "epoch:673, Loss_train:0.11, Loss_test:0.33\n",
            "epoch:674, Loss_train:0.09, Loss_test:0.39\n",
            "epoch:675, Loss_train:0.10, Loss_test:0.36\n",
            "epoch:676, Loss_train:0.15, Loss_test:0.34\n",
            "epoch:677, Loss_train:0.48, Loss_test:0.60\n",
            "epoch:678, Loss_train:0.24, Loss_test:0.51\n",
            "epoch:679, Loss_train:0.11, Loss_test:0.33\n",
            "epoch:680, Loss_train:0.22, Loss_test:0.39\n",
            "epoch:681, Loss_train:0.13, Loss_test:0.34\n",
            "epoch:682, Loss_train:0.10, Loss_test:0.33\n",
            "epoch:683, Loss_train:0.16, Loss_test:0.36\n",
            "epoch:684, Loss_train:0.17, Loss_test:0.40\n",
            "epoch:685, Loss_train:0.13, Loss_test:0.37\n",
            "epoch:686, Loss_train:0.14, Loss_test:0.34\n",
            "epoch:687, Loss_train:0.16, Loss_test:0.37\n",
            "epoch:688, Loss_train:0.16, Loss_test:0.33\n",
            "epoch:689, Loss_train:0.16, Loss_test:0.39\n",
            "epoch:690, Loss_train:0.25, Loss_test:0.37\n",
            "epoch:691, Loss_train:0.13, Loss_test:0.32\n",
            "epoch:692, Loss_train:0.17, Loss_test:0.31\n",
            "epoch:693, Loss_train:0.11, Loss_test:0.32\n",
            "epoch:694, Loss_train:0.12, Loss_test:0.31\n",
            "epoch:695, Loss_train:0.22, Loss_test:0.34\n",
            "epoch:696, Loss_train:0.27, Loss_test:0.39\n",
            "epoch:697, Loss_train:0.31, Loss_test:0.47\n",
            "epoch:698, Loss_train:0.57, Loss_test:0.73\n",
            "epoch:699, Loss_train:0.75, Loss_test:0.62\n",
            "epoch:700, Loss_train:0.14, Loss_test:0.34\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss 값 plot\n",
        "plt.figure()\n",
        "plt.plot(train_loss, label='train')\n",
        "plt.plot(test_loss, label='test')\n",
        "plt.title('Model loss')\n",
        "plt.legend(loc= 'upper right')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "KeQwutlHEI08",
        "outputId": "980596f6-924a-4191-a568-fc409c11f3cf"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}